{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>This is a reproduction, with a little change, of the content in the following link: http://www.nltk.org/book/ch01.html</b>. It can be useful for who want to learn about NLTK with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Language Processing and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Getting Started with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-9.0.1-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 852kB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 8.1.2\n",
      "    Uninstalling pip-8.1.2:\n",
      "      Successfully uninstalled pip-8.1.2\n",
      "Successfully installed pip-9.0.1\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.2.4.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 979kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.5/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/79/8b/2a/b2da7fce57a1fd9b20b08fa8800c83b6fde62af9e880722e29\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.4\n",
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> all\n",
      "    Downloading collection 'all'\n",
      "       | \n",
      "       | Downloading package abc to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/abc.zip.\n",
      "       | Downloading package alpino to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/alpino.zip.\n",
      "       | Downloading package biocreative_ppi to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/biocreative_ppi.zip.\n",
      "       | Downloading package brown to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/brown.zip.\n",
      "       | Downloading package brown_tei to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/brown_tei.zip.\n",
      "       | Downloading package cess_cat to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cess_cat.zip.\n",
      "       | Downloading package cess_esp to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cess_esp.zip.\n",
      "       | Downloading package chat80 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/chat80.zip.\n",
      "       | Downloading package city_database to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/city_database.zip.\n",
      "       | Downloading package cmudict to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cmudict.zip.\n",
      "       | Downloading package comparative_sentences to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/comparative_sentences.zip.\n",
      "       | Downloading package comtrans to /home/jovyan/nltk_data...\n",
      "       | Downloading package conll2000 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/conll2000.zip.\n",
      "       | Downloading package conll2002 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/conll2002.zip.\n",
      "       | Downloading package conll2007 to /home/jovyan/nltk_data...\n",
      "       | Downloading package crubadan to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/crubadan.zip.\n",
      "       | Downloading package dependency_treebank to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/dependency_treebank.zip.\n",
      "       | Downloading package dolch to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/dolch.zip.\n",
      "       | Downloading package europarl_raw to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/europarl_raw.zip.\n",
      "       | Downloading package floresta to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/floresta.zip.\n",
      "       | Downloading package framenet_v15 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v15.zip.\n",
      "       | Downloading package framenet_v17 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v17.zip.\n",
      "       | Downloading package gazetteers to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/gazetteers.zip.\n",
      "       | Downloading package genesis to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/genesis.zip.\n",
      "       | Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/gutenberg.zip.\n",
      "       | Downloading package ieer to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ieer.zip.\n",
      "       | Downloading package inaugural to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/inaugural.zip.\n",
      "       | Downloading package indian to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/indian.zip.\n",
      "       | Downloading package jeita to /home/jovyan/nltk_data...\n",
      "       | Downloading package kimmo to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/kimmo.zip.\n",
      "       | Downloading package knbc to /home/jovyan/nltk_data...\n",
      "       | Downloading package lin_thesaurus to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/lin_thesaurus.zip.\n",
      "       | Downloading package mac_morpho to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/mac_morpho.zip.\n",
      "       | Downloading package machado to /home/jovyan/nltk_data...\n",
      "       | Downloading package masc_tagged to /home/jovyan/nltk_data...\n",
      "       | Downloading package moses_sample to /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/moses_sample.zip.\n",
      "       | Downloading package movie_reviews to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/movie_reviews.zip.\n",
      "       | Downloading package names to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/names.zip.\n",
      "       | Downloading package nombank.1.0 to /home/jovyan/nltk_data...\n",
      "       | Downloading package nps_chat to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/nps_chat.zip.\n",
      "       | Downloading package omw to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/omw.zip.\n",
      "       | Downloading package opinion_lexicon to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/opinion_lexicon.zip.\n",
      "       | Downloading package paradigms to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/paradigms.zip.\n",
      "       | Downloading package pil to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pil.zip.\n",
      "       | Downloading package pl196x to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pl196x.zip.\n",
      "       | Downloading package ppattach to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ppattach.zip.\n",
      "       | Downloading package problem_reports to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/problem_reports.zip.\n",
      "       | Downloading package propbank to /home/jovyan/nltk_data...\n",
      "       | Downloading package ptb to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ptb.zip.\n",
      "       | Downloading package product_reviews_1 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_1.zip.\n",
      "       | Downloading package product_reviews_2 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_2.zip.\n",
      "       | Downloading package pros_cons to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pros_cons.zip.\n",
      "       | Downloading package qc to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/qc.zip.\n",
      "       | Downloading package reuters to /home/jovyan/nltk_data...\n",
      "       | Downloading package rte to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/rte.zip.\n",
      "       | Downloading package semcor to /home/jovyan/nltk_data...\n",
      "       | Downloading package senseval to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/senseval.zip.\n",
      "       | Downloading package sentiwordnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sentiwordnet.zip.\n",
      "       | Downloading package sentence_polarity to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sentence_polarity.zip.\n",
      "       | Downloading package shakespeare to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/shakespeare.zip.\n",
      "       | Downloading package sinica_treebank to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sinica_treebank.zip.\n",
      "       | Downloading package smultron to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/smultron.zip.\n",
      "       | Downloading package state_union to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/state_union.zip.\n",
      "       | Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/stopwords.zip.\n",
      "       | Downloading package subjectivity to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/subjectivity.zip.\n",
      "       | Downloading package swadesh to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/swadesh.zip.\n",
      "       | Downloading package switchboard to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/switchboard.zip.\n",
      "       | Downloading package timit to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/timit.zip.\n",
      "       | Downloading package toolbox to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/toolbox.zip.\n",
      "       | Downloading package treebank to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/treebank.zip.\n",
      "       | Downloading package twitter_samples to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/twitter_samples.zip.\n",
      "       | Downloading package udhr to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/udhr.zip.\n",
      "       | Downloading package udhr2 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/udhr2.zip.\n",
      "       | Downloading package unicode_samples to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/unicode_samples.zip.\n",
      "       | Downloading package universal_treebanks_v20 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package verbnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/verbnet.zip.\n",
      "       | Downloading package webtext to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/webtext.zip.\n",
      "       | Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/wordnet.zip.\n",
      "       | Downloading package wordnet_ic to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/wordnet_ic.zip.\n",
      "       | Downloading package words to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/words.zip.\n",
      "       | Downloading package ycoe to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ycoe.zip.\n",
      "       | Downloading package rslp to /home/jovyan/nltk_data...\n",
      "       |   Unzipping stemmers/rslp.zip.\n",
      "       | Downloading package hmm_treebank_pos_tagger to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/hmm_treebank_pos_tagger.zip.\n",
      "       | Downloading package maxent_treebank_pos_tagger to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "       | Downloading package universal_tagset to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/universal_tagset.zip.\n",
      "       | Downloading package maxent_ne_chunker to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "       | Downloading package punkt to /home/jovyan/nltk_data...\n",
      "       |   Unzipping tokenizers/punkt.zip.\n",
      "       | Downloading package book_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/book_grammars.zip.\n",
      "       | Downloading package sample_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/sample_grammars.zip.\n",
      "       | Downloading package spanish_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/spanish_grammars.zip.\n",
      "       | Downloading package basque_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/basque_grammars.zip.\n",
      "       | Downloading package large_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/large_grammars.zip.\n",
      "       | Downloading package tagsets to /home/jovyan/nltk_data...\n",
      "       |   Unzipping help/tagsets.zip.\n",
      "       | Downloading package snowball_data to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package bllip_wsj_no_aux to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "       | Downloading package word2vec_sample to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/word2vec_sample.zip.\n",
      "       | Downloading package panlex_swadesh to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package mte_teip5 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/mte_teip5.zip.\n",
      "       | Downloading package averaged_perceptron_tagger to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "       | Downloading package perluniprops to /home/jovyan/nltk_data...\n",
      "       |   Unzipping misc/perluniprops.zip.\n",
      "       | Downloading package nonbreaking_prefixes to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "       | Downloading package vader_lexicon to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package porter_test to /home/jovyan/nltk_data...\n",
      "       |   Unzipping stemmers/porter_test.zip.\n",
      "       | Downloading package wmt15_eval to /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/wmt15_eval.zip.\n",
      "       | Downloading package mwa_ppdb to /home/jovyan/nltk_data...\n",
      "       |   Unzipping misc/mwa_ppdb.zip.\n",
      "       | \n",
      "     Done downloading collection all\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install nltk:\n",
    "## choose \"d\" for downlaod , then tap 'all' to download all packages. Once finished, to verify everthing was OK tap \"u\" \n",
    "\n",
    "##(if you get :Nothing to update it means :) otherwise :(. tap q to quit\n",
    "!pip install --upgrade pip\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is downloaded to your machine, you can load some of it using the Python interpreter. The first step is to type a special command at the Python prompt which tells the interpreter to load some texts for us to explore: from nltk.book import *. This says \"from NLTK's book module, load all items.\" The book module contains all the data you will need as you read this chapter. After printing a welcome message, it loads the text of several books (this will take a few seconds). Here's the command again, together with the output that you will see. Take care to get spelling and punctuation right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time we want to find out about these texts, we just have to enter their names at the Python prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can use the Python interpreter, and have some data to work with, we're ready to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3   Searching Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to examine the context of a text apart from simply reading it. A <b>concordance</b> view shows us every occurrence of a given word, together with some context. Here we look up the word monstrous in Moby Dick by entering text1 followed by a period, then the term concordance, and then placing \"monstrous\" in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>The first time you use a concordance on a particular text, it takes a few extra seconds to build an index so that subsequent searches are fast.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<b>Note</b>:\n",
    "\n",
    "<b>Your Turn</b>: Try searching for other words; to save re-typing, you might be able to use up-arrow, Ctrl-up-arrow or Alt-p to access the previous command and modify the word being searched. You can also try searches on some of the other texts we have included. For example, search Sense and Sensibility for the word affection, using  text2.concordance(\"affection\"). Search the book of Genesis to find out how long some people lived, using text3.concordance(\"lived\"). You could look at text4, the Inaugural Address Corpus, to see examples of English going back to 1789, and search for words like nation, terror, god to see how these words have been used differently over time. We've also included text5, the NPS Chat Corpus: search this for unconventional words like im, ur, lol. (Note that this corpus is uncensored!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 79 matches:\n",
      ", however , and , as a mark of his affection for the three girls , he left them\n",
      "t . It was very well known that no affection was ever supposed to exist between\n",
      "deration of politeness or maternal affection on the side of the former , the tw\n",
      "d the suspicion -- the hope of his affection for me may warrant , without impru\n",
      "hich forbade the indulgence of his affection . She knew that his mother neither\n",
      "rd she gave one with still greater affection . Though her late conversation wit\n",
      " can never hope to feel or inspire affection again , and if her home be uncomfo\n",
      "m of the sense , elegance , mutual affection , and domestic comfort of the fami\n",
      ", and which recommended him to her affection beyond every thing else . His soci\n",
      "ween the parties might forward the affection of Mr . Willoughby , an equally st\n",
      " the most pointed assurance of her affection . Elinor could not be surprised at\n",
      "he natural consequence of a strong affection in a young and ardent mind . This \n",
      " opinion . But by an appeal to her affection for her mother , by representing t\n",
      " every alteration of a place which affection had established as perfect with hi\n",
      "e will always have one claim of my affection , which no other can possibly shar\n",
      "f the evening declared at once his affection and happiness . \" Shall we see you\n",
      "ause he took leave of us with less affection than his usual behaviour has shewn\n",
      "ness .\" \" I want no proof of their affection ,\" said Elinor ; \" but of their en\n",
      "onths , without telling her of his affection ;-- that they should part without \n",
      "ould be the natural result of your affection for her . She used to be all unres\n",
      "distinguished Elinor by no mark of affection . Marianne saw and listened with i\n",
      "th no inclination for expense , no affection for strangers , no profession , an\n",
      "till distinguished her by the same affection which once she had felt no doubt o\n",
      "al of her confidence in Edward ' s affection , to the remembrance of every mark\n",
      " was made ? Had he never owned his affection to yourself ?\" \" Oh , no ; but if \n"
     ]
    }
   ],
   "source": [
    "text2.concordance(\"affection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 38 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "text3.concordance(\"lived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 21 of 21 matches:\n",
      "k up PART no i dont want daughters !! ur annoying . ACTION Now Playing - Cradl\n",
      "ooo U92 !!!!!! . ACTION U1370 watches ur nad with a stick . ca u U23 ewwww lol\n",
      "er lip . Meep . ACTION is resisting . ur female right lol U115 beeeeehave Reme\n",
      " geeshh ... two kids fighting ! whats ur major i probably sucks in summer too \n",
      "II Men scorpions rock ... lol what is ur job me too U11 hehe went to manhattan\n",
      "e no one i like to say if u have done ur time then that is that U42 Ok U37 , i\n",
      "hat a ride JOIN ty ty cheers babes .. ur the first to follow up with the pseud\n",
      " charger \\ty LoL yeah ;-) well i hope ur doing ok .. i 'm dojn fine babe . . g\n",
      " gonna rock up soojn and rob u of all ur ' candy ' :) as long as you are happy\n",
      "genital warts ? LoL moped U28 ?.. ohh ur a real man i had a moped once yup heh\n",
      "b-day is in 5 days =( PART LOL U35 no ur nawt yup your gay lmao U37 dang come \n",
      " people talk to me anymore oh because ur gay . PART PART . ACTION = U58 . Man \n",
      " om hi U73 heya U7 ! h shit i get all ur money now fawker ok girl lol JOIN ed \n",
      "hat tired huh U66 ? lol U75 ... bring ur pillow get comfy U70 yep , off to bed\n",
      "talked to hi sean . ACTION whispers : ur a douche . who PART . ACTION whispers\n",
      "ew england usa ? U7 .. it adds wax to ur clothes .. u think cottons breathe ?.\n",
      "ver knew what flavor to get specially ur towels lol U31 < whistles > U34 U39 I\n",
      "cks out U7 s pic JOIN PART U41 Hi U41 ur gettin pretty savvy there U39 ahhh ..\n",
      "om ? brb U30 a week .. heck a day and ur problem there , U30 ??? Hi U34 hartfo\n",
      " JOIN U57 Whats really good room JOIN ur telllin me hey any uk girls her ? JOI\n",
      "JOIN PART JOIN JOIN yea guitar rocker ur kool u lil guitar rocker PART whats e\n"
     ]
    }
   ],
   "source": [
    "text5.concordance(\"ur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> You can see that ur can be used before verbs, nouns, prepositions,....</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've spent a little while examining these texts, we hope you have a new sense of the richness and diversity of language. In the next chapter you will learn how to access a broader range of text, including text in languages other than English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concordance permits us to see words in context. For example, we saw that monstrous occurred in contexts such as the ___ pictures and a ___ size . What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:( search for all w1ww2 then all w' so that we have w1w'w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyrannical vexatious maddens uncommon untoward imperial perilous\n",
      "careful abundant modifies lamentable determined reliable christian few\n",
      "subtly wise loving lazy domineering\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very exceedingly heartily so remarkably sweet a amazingly vast good as\n",
      "great extremely\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Observe that we get different results for different texts. Austen uses this word quite differently from Melville; for her, monstrous has positive connotations, and sometimes functions as an intensifier like the word very.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term common_contexts allows us to examine just the contexts that are shared by two or more words, such as monstrous and very. We have to enclose these words by square brackets as well as parentheses, and separate them with a comma:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_pictures\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts([\"monstrous\", \"true\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>This result tells us that the phrases \"the monstrous pictures\" and \"the true pictures\" both appear in Moby Dick.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<b>Note</b>:\n",
    "\n",
    "<b>Your Turn</b>: Pick another pair of words and compare their usage in two different texts, using the similar() and common_contexts() functions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government power freedom congress peace all liberty war them america\n",
      "duty which country progress man it justice purpose security nations\n"
     ]
    }
   ],
   "source": [
    "text4.similar(\"life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of_that of_will of_to of_the the_and of_not the_of of_we human_we\n",
      "own_and that_is human_and of_in of_of of_is of_and of_it\n"
     ]
    }
   ],
   "source": [
    "text4.common_contexts([\"life\",\"freedom\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ears that mind music mystery daughter who penis homeboys uniform bad\n",
      "spelling gift girl love fav virgin pop bot petition\n"
     ]
    }
   ],
   "source": [
    "text5.similar(\"life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_join\n"
     ]
    }
   ],
   "source": [
    "text5.common_contexts([\"life\",\"room\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>the usage of a words depends on the text where it is used</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text. In 1.2 we see some striking patterns of word usage over the last 220 years (in an artificial text constructed by joining the texts of the Inaugural Address Corpus end-to-end). You can produce this plot as shown below. You might like to try more words (e.g., liberty, constitution), and different texts. Can you predict the dispersion of a word before you view it? As before, take care to get the quotes, commas, brackets and parentheses exactly right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEWCAYAAABWn/G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns6yceMzMLCsnHjMzy+r/A1/Z2Ybe7k83AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a0c8008d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>It plot occurence of each words along the entire text</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just for fun, let's try generating some random text in the various styles we have just seen. To do this, we type the name of the text followed by the term generate. (We need to include the parentheses, but there's nothing that goes between them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t=text3.generate() # The generate() method is not available in NLTK 3.0 but will be reinstated in a subsequent version. \n",
    "#That's why it shows aan error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4   Counting Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The most obvious fact about texts that emerges from the preceding examples is that they differ in the vocabulary they use. In this section we will see how to use the computer to count the words in a text in a variety of useful ways. As before, you will jump right in and experiment with the Python interpreter, even though you may not have studied Python systematically yet. Test your understanding by modifying the examples, and trying the exercises at the end of the chapter.</br>\n",
    "\n",
    "Let's begin by finding out the length of a text from start to finish, in terms of the words and punctuation symbols that appear. We use the term len to get the length of something, which we'll apply here to the book of Genesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Genesis has 44,764 words and punctuation symbols, or \"tokens.\" A token is the technical name for a sequence of characters — such as hairy, his, or :) — that we want to treat as a group. When we count the number of tokens in a text, say, the phrase to be or not to be, we are counting occurrences of these sequences. Thus, in our example phrase there are two occurrences of to, two of be, and one each of or and not. But there are only four distinct vocabulary items in this phrase. How many distinct words does the book of Genesis contain? To work this out in Python, we have to pose the question slightly differently. The vocabulary of a text is just the set of tokens that it uses, since in a set, all duplicates are collapsed together. In Python we can obtain the vocabulary items of text3 with the command:  set(text3). When you do this, many screens of words will fly past. Now try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>By wrapping sorted() around the Python expression set(text3) [1], we obtain a sorted list of vocabulary items, beginning with various punctuation symbols and continuing with words starting with A. All capitalized words precede lowercase words. We discover the size of the vocabulary indirectly, by asking for the number of items in the set, and again we can use len to obtain this number [2]. Although it has 44,764 tokens, this book has only 2,789 distinct words, or <b>\"word types.\"</b> A word type is the form or spelling of the word independently of its specific occurrences in a text — that is, the word considered as a unique item of vocabulary. Our count of 2,789 items will include punctuation symbols, so we will generally call these unique items <b>types</b> instead of word types.\n",
    "\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate a measure of the lexical richness of the text. The next example shows us that the number of distinct words is just 6% of the total number of words, or equivalently that each word is used 16 times on average (remember if you're using Python 2, to start with from __future__ import division)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))/len(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's focus on particular words. We can count how often a word occurs in a text, and compute what percentage of the text is taken up by a specific word:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*text4.count(\"a\")/len(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>\n",
    "\n",
    "Your Turn: How many times does the word lol appear in text5? How much is this as a percentage of the total number of words in this text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 0.015640968673628082, 45010)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.count(\"lol\"),text5.count(\"lol\")/len(text5),len(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to repeat such calculations on several texts, but it is tedious to keep retyping the formula. Instead, you can come up with your own name for a task, like \"lexical_diversity\" or \"percentage\", and associate it with a block of code. Now you only have to type a short name instead of one or more complete lines of Python code, and you can re-use it as often as you like. The block of code that does a task for us is called a function, and we define a short name for our function with the keyword def. The next example shows how to define two new functions, lexical_diversity() and  percentage():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text))/len(text)\n",
    "\n",
    "\n",
    "def percentage(count,total):\n",
    "    return 100*count/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the definition of lexical_diversity() [1], we specify a parameter named text . This parameter is a \"placeholder\" for the actual text whose lexical diversity we want to compute, and reoccurs in the block of code that will run when the function is used [2]. Similarly, percentage() is defined to take two parameters, named count and total [3].\n",
    "\n",
    "Once Python knows that lexical_diversity() and percentage() are the names for specific blocks of code, we can go ahead and use these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06692970116993173"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'),len(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we use or call a function such as lexical_diversity() by typing its name, followed by an open parenthesis, the name of the text, and then a close parenthesis. These parentheses will show up often; their role is to separate the name of a task — such as lexical_diversity() — from the data that the task is to be performed on — such as text3. The data value that we place in the parentheses when we call a function is an argument to the function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already encountered several functions in this chapter, such as len(), set(), and sorted(). By convention, we will always add an empty pair of parentheses after a function name, as in len(), just to make clear that what we are talking about is a function rather than some other kind of Python expression. Functions are an important concept in programming, and we only mention them at the outset to give newcomers a sense of the power and creativity of programming. Don't worry if you find it a bit confusing right now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we'll see how to use functions when tabulating data, as in 1.1. Each row of the table will involve the same computation but with different data, and we'll do this repetitive work using a function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[](diversity.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](diversity.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.   A Closer Look at Python: Texts as Lists of Words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've seen some important elements of the Python programming language. Let's take a few moments to review them systematically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1   Lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a text? At one level, it is a sequence of symbols on a page such as this one. At another level, it is a sequence of chapters, made up of a sequence of sections, where each section is a sequence of paragraphs, and so on. However, for our purposes, we will think of a text as nothing more than a sequence of words and punctuation. Here's how we represent text in Python, in this case the opening sentence of Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Call', 'me', 'Ishmael', '.', 'some'], 1.0, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1, lexical_diversity(sent1), sent1.append(\"some\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2   Indexing Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('awaken', 173)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4[173], text4.index(\"awaken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexes are a common way to access the words of a text, or, more generally, the elements of any list. Python permits us to access sublists as well, extracting manageable pieces of language from large texts, a technique known as slicing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lmao', 'U7', '!!!', '.', 'ACTION', 'laughs', '.', ':)', 'PART']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5[1000:1009]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4   Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the methods we used to access the elements of a list also work with individual words, or strings. For example, we can assign a string to a variable [1], index a string [2], and slice a string [3]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('M', 'Mo')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name='Monty'\n",
    "name[0], name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty!'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name+'!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MontyMonty'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join the words of a list to make a single string, or split a string into a list, as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['Monty','Python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Python']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty Python'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.   Computing with Language: Simple Statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to our exploration of the ways we can bring our computational resources to bear on large quantities of text. We began this discussion in 1, and saw how to search for words in context, how to compile the vocabulary of a text, how to generate random text in the same style, and so on.\n",
    "\n",
    "In this section we pick up the question of what makes a text distinct, and use automatic methods to find characteristic words and expressions of a text. As in 1, you can try new features of the Python language by copying them into the interpreter, and you'll learn about these features systematically in the following section.\n",
    "\n",
    "Before continuing further, you might like to check your understanding of the last section by predicting the output of the following code. You can use the interpreter to check whether you got it right. If you're not sure how to do this task, it would be a good idea to review the previous section before continuing further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done','more', 'is', 'said', 'than', 'done','Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'After', 'Z', 'all', 'and', 'done', 'is', 'more', 'said', 'than'}, 12, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens=set(saying)# set(saying) keeps just unique words ( if words is repeated many times we keep one word)\n",
    "tokens,len(saying),len(tokens)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After', 'Z', 'all', 'and', 'done', 'is', 'more', 'said', 'than']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens=sorted(tokens)  # sort all words ( starting with A-Z then a-z)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said', 'than']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[-2:] # the last two words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1   Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we automatically identify the words of a text that are most informative about the topic and genre of the text? Imagine how you might go about finding the 50 most frequent words of a book. One method would be to keep a tally for each vocabulary item, like that shown in 3.1. The tally would need thousands of rows, and it would be an exceedingly laborious process — so laborious that we would rather assign the task to a machine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tally.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table in 3.1 is known as a frequency distribution, and it tells us the frequency of each vocabulary item in the text. (In general, it could count any kind of observable event.) It is a \"distribution\" because it tells us how the total number of word tokens in the text are distributed across the vocabulary items. Since we often need frequency distributions in language processing, NLTK provides built-in support for them. Let's use a FreqDist to find the 50 most frequent words of Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n",
      "906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist=FreqDist(text1)\n",
    "print(fdist)\n",
    "print(fdist['whale'])# whale :a very large fish-like mammal that lives in the ocean\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>\n",
    "\n",
    "Your Turn: Try the preceding frequency distribution example for yourself, for text2. Be careful to use the correct parentheses and uppercase letters. If you get an error message NameError: name 'FreqDist' is not defined, you need to start your work with from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6833 samples and 141576 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 9397),\n",
       " ('to', 4063),\n",
       " ('.', 3975),\n",
       " ('the', 3861),\n",
       " ('of', 3565),\n",
       " ('and', 3350),\n",
       " ('her', 2436),\n",
       " ('a', 2043),\n",
       " ('I', 2004),\n",
       " ('in', 1904),\n",
       " ('was', 1846),\n",
       " ('it', 1568),\n",
       " ('\"', 1506),\n",
       " (';', 1419),\n",
       " ('she', 1333),\n",
       " ('be', 1305),\n",
       " ('that', 1297),\n",
       " ('for', 1234),\n",
       " ('not', 1212),\n",
       " ('as', 1179)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2=FreqDist(text2)\n",
    "print(fdist2)\n",
    "fdist2.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do any words produced in the last example help us grasp the topic or genre of this text? Only one word, whale, is slightly informative! It occurs over 900 times. The rest of the words tell us nothing about the text; they're just English \"plumbing.\" What proportion of the text is taken up with such words? We can generate a cumulative frequency plot for these words, using fdist1.plot(50, cumulative=True), to produce the graph in 3.2. These 50 words account for nearly half the book!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEdCAYAAADacco9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a4d46bc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260819\n"
     ]
    }
   ],
   "source": [
    "fdist.plot(50,cumulative=True)\n",
    "print(len(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the frequent words don't help us, how about the words that occur once only, the so-called hapaxes? View them by typing fdist1.hapaxes(). This list contains lexicographer, cetological, contraband, expostulations, and about 9,000 others. It seems that there are too many rare words, and without seeing the context we probably can't guess what half of the hapaxes mean in any case! Since neither frequent nor infrequent words help, we need to try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['navigator',\n",
       " 'rats',\n",
       " 'comfortableness',\n",
       " 'assurance',\n",
       " 'Herculaneum',\n",
       " 'despite',\n",
       " 'immaterial',\n",
       " 'stumbling',\n",
       " '56',\n",
       " 'spermy',\n",
       " 'mow',\n",
       " 'CHIEF',\n",
       " 'BURST',\n",
       " 'rigorous',\n",
       " 'Nail',\n",
       " 'loam',\n",
       " 'pinny',\n",
       " 'uneventfulness',\n",
       " 'demijohn',\n",
       " 'ached',\n",
       " 'Versailles',\n",
       " 'display',\n",
       " 'farthing',\n",
       " 'luff',\n",
       " 'inequality',\n",
       " 'moderns',\n",
       " 'assembly',\n",
       " 'illimitably',\n",
       " 'vexatious',\n",
       " 'shabbily',\n",
       " 'radiant',\n",
       " 'ascertaining',\n",
       " 'carlines',\n",
       " 'selectest',\n",
       " 'crave',\n",
       " 'counsels',\n",
       " 'rendered',\n",
       " 'scooped',\n",
       " 'Fashioned',\n",
       " 'Arion',\n",
       " 'sidelingly',\n",
       " 'reverberations',\n",
       " 'relent',\n",
       " 'Supreme',\n",
       " 'supernal',\n",
       " 'punish',\n",
       " 'bashful',\n",
       " 'pirouetting',\n",
       " 'spawned',\n",
       " 'Goat',\n",
       " 'leopard',\n",
       " 'exerted',\n",
       " 'gluepots',\n",
       " 'obeyest',\n",
       " 'Herman',\n",
       " 'salutes',\n",
       " 'slided',\n",
       " 'ibis',\n",
       " 'spotlessness',\n",
       " 'Mad',\n",
       " 'Valparaiso',\n",
       " 'proverbial',\n",
       " 'bigot',\n",
       " 'Camel',\n",
       " 'bedraggled',\n",
       " 'Bourbons',\n",
       " 'cosmopolite',\n",
       " 'Baling',\n",
       " 'impresses',\n",
       " 'Philologically',\n",
       " 'nosegays',\n",
       " 'rockets',\n",
       " 'unequal',\n",
       " 'clove',\n",
       " 'methods',\n",
       " 'Birmah',\n",
       " 'unbuckling',\n",
       " 'threepence',\n",
       " 'mammis',\n",
       " 'demselves',\n",
       " 'ELLERY',\n",
       " 'enactment',\n",
       " 'wandered',\n",
       " 'hospitalities',\n",
       " 'shelves',\n",
       " 'unprepared',\n",
       " 'dares',\n",
       " 'dedication',\n",
       " 'dissolutions',\n",
       " 'sack',\n",
       " 'Jollily',\n",
       " 'Hydriote',\n",
       " 'discharging',\n",
       " 'poser',\n",
       " 'babbling',\n",
       " 'sourceless',\n",
       " 'bowings',\n",
       " 'Late',\n",
       " 'boatswain',\n",
       " 'Puritans',\n",
       " 'purr',\n",
       " 'acuteness',\n",
       " 'suffusingly',\n",
       " 'fictitiously',\n",
       " 'rapture',\n",
       " 'sublimer',\n",
       " 'lamentable',\n",
       " 'bandied',\n",
       " 'Names',\n",
       " 'scoot',\n",
       " 'attribute',\n",
       " 'resided',\n",
       " 'freshened',\n",
       " 'illuminating',\n",
       " 'undigested',\n",
       " 'cobbler',\n",
       " 'cost',\n",
       " 'crannies',\n",
       " 'whitenesses',\n",
       " 'listened',\n",
       " 'Harto',\n",
       " 'burgher',\n",
       " 'filial',\n",
       " 'ravens',\n",
       " 'wampum',\n",
       " 'unceremoniously',\n",
       " 'fists',\n",
       " 'dazed',\n",
       " 'cleansing',\n",
       " 'Rat',\n",
       " 'echoes',\n",
       " 'unwinding',\n",
       " 'CHRONICLER',\n",
       " 'contended',\n",
       " 'hag',\n",
       " 'vouchers',\n",
       " 'solicitously',\n",
       " 'Norse',\n",
       " 'Arm',\n",
       " 'transferringly',\n",
       " 'arrogance',\n",
       " 'experiments',\n",
       " 'pursed',\n",
       " 'Belial',\n",
       " 'ruling',\n",
       " 'languishing',\n",
       " 'imperative',\n",
       " 'whimsiness',\n",
       " 'raved',\n",
       " 'purposeless',\n",
       " 'zag',\n",
       " 'fastener',\n",
       " 'amend',\n",
       " 'infecting',\n",
       " 'Cattegat',\n",
       " 'WHALESHIPS',\n",
       " 'Brahmins',\n",
       " 'Nicholas',\n",
       " 'palisades',\n",
       " 'gibbering',\n",
       " 'Circassian',\n",
       " 'angularly',\n",
       " 'Lighting',\n",
       " 'holdest',\n",
       " 'Nimbly',\n",
       " 'Slip',\n",
       " 'perpetuates',\n",
       " 'Impiety',\n",
       " 'stowaways',\n",
       " 'breezelessness',\n",
       " 'medals',\n",
       " 'proverbially',\n",
       " 'practices',\n",
       " 'Vaticans',\n",
       " 'thinkest',\n",
       " 'stifling',\n",
       " 'overmanned',\n",
       " 'blusterer',\n",
       " 'relying',\n",
       " 'sigh',\n",
       " 'mountaineers',\n",
       " 'CANNY',\n",
       " 'provincial',\n",
       " 'axles',\n",
       " 'waterproof',\n",
       " 'rejection',\n",
       " 'throttle',\n",
       " 'lotions',\n",
       " 'habituated',\n",
       " 'Sway',\n",
       " 'MINISTER',\n",
       " 'ing',\n",
       " 'CLEAN',\n",
       " 'gushing',\n",
       " 'dietetically',\n",
       " 'comforted',\n",
       " 'wantonly',\n",
       " 'wived',\n",
       " 'Morrel',\n",
       " 'lege',\n",
       " 'Maccabees',\n",
       " 'glim',\n",
       " 'Borneo',\n",
       " 'countrymen',\n",
       " 'Aside',\n",
       " 'lonesomeness',\n",
       " 'acknowledges',\n",
       " 'Friend',\n",
       " 'extravaganzas',\n",
       " 'plaintiveness',\n",
       " 'cones',\n",
       " 'Bungle',\n",
       " 'veracious',\n",
       " 'outspreadingly',\n",
       " 'throbbings',\n",
       " 'unpainted',\n",
       " 'throttled',\n",
       " 'clamorous',\n",
       " 'guinea',\n",
       " 'propulsion',\n",
       " 'cleats',\n",
       " 'parti',\n",
       " 'gaudiest',\n",
       " 'repulses',\n",
       " 'Paean',\n",
       " 'sunbeam',\n",
       " 'Shaker',\n",
       " 'cycloid',\n",
       " 'miserly',\n",
       " 'adhesiveness',\n",
       " '29',\n",
       " 'allegorical',\n",
       " 'Instances',\n",
       " 'filers',\n",
       " 'prelusive',\n",
       " 'begets',\n",
       " 'probed',\n",
       " 'brush',\n",
       " 'forlornness',\n",
       " 'provident',\n",
       " 'itch',\n",
       " 'whalin',\n",
       " 'inarticulate',\n",
       " 'Wife',\n",
       " 'paradise',\n",
       " 'whirls',\n",
       " 'Unhinge',\n",
       " 'cinders',\n",
       " 'donned',\n",
       " 'unsolved',\n",
       " 'odoriferous',\n",
       " 'EZEKIEL',\n",
       " 'pitchpoler',\n",
       " 'merrily',\n",
       " 'NEWSPAPER',\n",
       " 'Pines',\n",
       " 'villa',\n",
       " 'sartainty',\n",
       " 'creativeness',\n",
       " 'blankets',\n",
       " 'clasped',\n",
       " 'equity',\n",
       " 'ulcerous',\n",
       " 'bounding',\n",
       " 'speeding',\n",
       " 'tie',\n",
       " '1793',\n",
       " 'magniloquent',\n",
       " 'slats',\n",
       " 'leper',\n",
       " 'contingencies',\n",
       " 'Titanic',\n",
       " 'savoury',\n",
       " 'texture',\n",
       " 'PORTUGUESE',\n",
       " 'Plum',\n",
       " 'uneven',\n",
       " 'protested',\n",
       " 'mannikin',\n",
       " 'Yorkshire',\n",
       " 'slaughter',\n",
       " 'Ingin',\n",
       " 'lotus',\n",
       " 'WATCH',\n",
       " 'rips',\n",
       " 'gardenny',\n",
       " 'serpentines',\n",
       " 'unappalled',\n",
       " 'professors',\n",
       " 'discolour',\n",
       " 'alewives',\n",
       " 'scarf',\n",
       " 'Arrayed',\n",
       " 'inlayings',\n",
       " 'gnashing',\n",
       " 'unload',\n",
       " 'aboriginalness',\n",
       " 'beseech',\n",
       " 'mocks',\n",
       " 'invert',\n",
       " 'parm',\n",
       " 'assistance',\n",
       " 'SEAMS',\n",
       " 'masks',\n",
       " 'noiselessly',\n",
       " 'defence',\n",
       " 'elbow',\n",
       " 'bowie',\n",
       " 'Seeva',\n",
       " '62',\n",
       " 'cooler',\n",
       " 'ermine',\n",
       " 'stubbornest',\n",
       " 'indite',\n",
       " 'peddlin',\n",
       " 'chipped',\n",
       " 'Warmest',\n",
       " '94',\n",
       " 'southwards',\n",
       " 'splashing',\n",
       " 'winking',\n",
       " 'Lowering',\n",
       " 'carcases',\n",
       " 'outdone',\n",
       " 'penal',\n",
       " 'revolves',\n",
       " 'FLAME',\n",
       " 'genteel',\n",
       " 'chargers',\n",
       " 'mannerly',\n",
       " 'Rarmai',\n",
       " 'Netherlands',\n",
       " 'fronting',\n",
       " 'viol',\n",
       " 'Frenchmen',\n",
       " 'pennons',\n",
       " 'decency',\n",
       " '35',\n",
       " 'deliverer',\n",
       " 'Jordan',\n",
       " 'bombazine',\n",
       " 'comber',\n",
       " 'Palace',\n",
       " 'creamed',\n",
       " 'bulks',\n",
       " 'incongruity',\n",
       " 'Wretched',\n",
       " 'insured',\n",
       " 'Consumptive',\n",
       " 'identify',\n",
       " 'volley',\n",
       " 'justify',\n",
       " 'unconditionally',\n",
       " 'reiterated',\n",
       " 'wavingly',\n",
       " 'bunched',\n",
       " 'PRESIDENCY',\n",
       " 'lament',\n",
       " 'warping',\n",
       " 'Thorkill',\n",
       " 'midships',\n",
       " 'gesticulated',\n",
       " 'Leap',\n",
       " 'risings',\n",
       " 'ducat',\n",
       " 'MCCULLOCH',\n",
       " 'untidy',\n",
       " 'chafed',\n",
       " 'Sands',\n",
       " 'fasces',\n",
       " 'court',\n",
       " 'Comparing',\n",
       " 'smuggling',\n",
       " 'screamed',\n",
       " 'foreground',\n",
       " 'abhorrent',\n",
       " 'celled',\n",
       " 'enthrone',\n",
       " 'overawing',\n",
       " 'oversee',\n",
       " 'Splice',\n",
       " 'opportunities',\n",
       " 'foaled',\n",
       " 'rambled',\n",
       " 'hideously',\n",
       " 'SEEN',\n",
       " 'loveliest',\n",
       " 'Face',\n",
       " 'twopence',\n",
       " 'Socratic',\n",
       " 'unbecomingness',\n",
       " 'atheism',\n",
       " 'antlers',\n",
       " 'Hollanders',\n",
       " 'popularize',\n",
       " 'adjust',\n",
       " 'semiweekly',\n",
       " 'pliable',\n",
       " 'XXXIX',\n",
       " 'Fa',\n",
       " 'brawniness',\n",
       " 'extend',\n",
       " 'garments',\n",
       " 'quarrelsome',\n",
       " 'bamboozle',\n",
       " 'mint',\n",
       " 'bounced',\n",
       " 'endurance',\n",
       " 'scramble',\n",
       " 'gauntleted',\n",
       " 'heartwoes',\n",
       " 'manikin',\n",
       " 'lodgings',\n",
       " 'compassion',\n",
       " 'iciness',\n",
       " 'Fernandes',\n",
       " 'booting',\n",
       " 'sentinelled',\n",
       " 'padlock',\n",
       " 'pier',\n",
       " 'heraldic',\n",
       " 'rapscallions',\n",
       " 'Silently',\n",
       " 'cabalistically',\n",
       " '24',\n",
       " 'trim',\n",
       " 'preciousness',\n",
       " 'speckled',\n",
       " 'doltish',\n",
       " 'mortalities',\n",
       " 'curls',\n",
       " 'tithe',\n",
       " 'ulceration',\n",
       " 'cabalistical',\n",
       " 'unfitted',\n",
       " 'SPLICE',\n",
       " 'birthmark',\n",
       " 'unstranded',\n",
       " 'occupants',\n",
       " 'drench',\n",
       " 'susceptible',\n",
       " 'adoption',\n",
       " 'beached',\n",
       " 'Corlaer',\n",
       " 'sequential',\n",
       " 'conveyance',\n",
       " 'irksome',\n",
       " 'thirteenth',\n",
       " 'Historians',\n",
       " 'surpassed',\n",
       " 'tougher',\n",
       " 'ingloriously',\n",
       " 'frequendy',\n",
       " 'mystifying',\n",
       " 'rout',\n",
       " 'quenchless',\n",
       " 'bullocks',\n",
       " 'Miracle',\n",
       " 'MAIN',\n",
       " 'retracing',\n",
       " 'refrigerators',\n",
       " 'undue',\n",
       " 'lovings',\n",
       " 'welding',\n",
       " 'celebrity',\n",
       " 'admonitory',\n",
       " 'shoaling',\n",
       " 'toasted',\n",
       " 'druggists',\n",
       " 'Jews',\n",
       " 'thrashing',\n",
       " 'workers',\n",
       " 'tips',\n",
       " 'butcher',\n",
       " 'lasts',\n",
       " 'shrewdness',\n",
       " 'countersunk',\n",
       " 'bet',\n",
       " 'Leeward',\n",
       " '96',\n",
       " 'balloon',\n",
       " 'THEE',\n",
       " 'bumping',\n",
       " 'menial',\n",
       " 'crept',\n",
       " 'giddy',\n",
       " 'Raphael',\n",
       " 'aggravate',\n",
       " 'recurred',\n",
       " 'Flukes',\n",
       " 'cutlet',\n",
       " 'Mississippies',\n",
       " 'nonplussed',\n",
       " 'tingles',\n",
       " 'KETOS',\n",
       " 'Ophites',\n",
       " 'upraising',\n",
       " 'needlessly',\n",
       " 'Cyclades',\n",
       " 'untattooed',\n",
       " 'Thanks',\n",
       " 'affronted',\n",
       " 'budding',\n",
       " 'banister',\n",
       " 'waxes',\n",
       " 'archangelical',\n",
       " 'Secretary',\n",
       " 'wavings',\n",
       " 'preside',\n",
       " 'mangles',\n",
       " 'immortals',\n",
       " 'jealousy',\n",
       " 'transfixedly',\n",
       " 'solo',\n",
       " 'inventors',\n",
       " 'Cognac',\n",
       " 'Bibliographical',\n",
       " 'Logan',\n",
       " 'overspread',\n",
       " 'Rousseau',\n",
       " 'monarch',\n",
       " 'divinity',\n",
       " 'vales',\n",
       " 'totality',\n",
       " 'suckingly',\n",
       " 'soladoes',\n",
       " 'centres',\n",
       " 'Dunfermline',\n",
       " 'tars',\n",
       " 'sleight',\n",
       " 'protecting',\n",
       " 'unobservant',\n",
       " 'Krusensterns',\n",
       " 'nondescript',\n",
       " 'overdone',\n",
       " 'manipulator',\n",
       " 'presumable',\n",
       " 'twiske',\n",
       " 'Wa',\n",
       " 'clammy',\n",
       " 'humph',\n",
       " 'garters',\n",
       " 'WHIFF',\n",
       " 'circumnavigated',\n",
       " 'underwent',\n",
       " 'Semiramis',\n",
       " 'Dar',\n",
       " 'HARPOONEERS',\n",
       " 'sketching',\n",
       " 'searches',\n",
       " 'individually',\n",
       " 'renouncing',\n",
       " 'Jumped',\n",
       " 'beginner',\n",
       " 'hems',\n",
       " 'wonderingly',\n",
       " 'remorse',\n",
       " 'wagon',\n",
       " 'punctures',\n",
       " 'curb',\n",
       " 'slatternly',\n",
       " 'Won',\n",
       " 'inveterate',\n",
       " 'sulphur',\n",
       " 'ink',\n",
       " 'subordinates',\n",
       " 'accommodated',\n",
       " 'tramping',\n",
       " 'meditativeness',\n",
       " 'FIGURED',\n",
       " 'struggled',\n",
       " 'squadrons',\n",
       " 'hares',\n",
       " 'waiving',\n",
       " 'tassels',\n",
       " 'Soothed',\n",
       " 'mazy',\n",
       " 'unwilling',\n",
       " 'Cash',\n",
       " 'punches',\n",
       " 'viceroy',\n",
       " 'simultaneous',\n",
       " 'pinmoney',\n",
       " 'ATTACKED',\n",
       " 'Denderah',\n",
       " 'pulls',\n",
       " 'jurisdiction',\n",
       " 'smiled',\n",
       " 'digestive',\n",
       " 'achieve',\n",
       " 'tiled',\n",
       " 'describes',\n",
       " 'scars',\n",
       " 'Balaene',\n",
       " 'Pythagoras',\n",
       " 'Canadian',\n",
       " 'influential',\n",
       " 'longed',\n",
       " 'senseless',\n",
       " 'legerdemain',\n",
       " 'Castaway',\n",
       " 'HARDY',\n",
       " 'Hill',\n",
       " 'APPLICATION',\n",
       " 'signification',\n",
       " 'cloak',\n",
       " 'quarantine',\n",
       " 'dedicating',\n",
       " 'curvicues',\n",
       " 'retains',\n",
       " 'malefactors',\n",
       " 'forking',\n",
       " 'gloating',\n",
       " 'Hall',\n",
       " 'housewives',\n",
       " 'Mesopotamian',\n",
       " 'precincts',\n",
       " 'bedwards',\n",
       " 'stride',\n",
       " 'emprise',\n",
       " 'unseamanlike',\n",
       " 'fiddler',\n",
       " 'educated',\n",
       " 'mediums',\n",
       " 'strains',\n",
       " 'passionately',\n",
       " 'breasted',\n",
       " 'willow',\n",
       " 'energies',\n",
       " 'thrill',\n",
       " 'barbarian',\n",
       " 'hish',\n",
       " 'supervision',\n",
       " 'unassuming',\n",
       " 'aldermen',\n",
       " 'forlornly',\n",
       " 'Articles',\n",
       " 'Tumbled',\n",
       " 'deaths',\n",
       " 'augmented',\n",
       " 'polish',\n",
       " 'stronghold',\n",
       " 'hopped',\n",
       " 'lectures',\n",
       " 'unprecedentedly',\n",
       " 'namelessly',\n",
       " 'aisle',\n",
       " 'wavy',\n",
       " 'onsets',\n",
       " 'snooze',\n",
       " 'unapprehensive',\n",
       " 'territorial',\n",
       " 'festoons',\n",
       " 'Beloved',\n",
       " 'Portugal',\n",
       " 'SORTS',\n",
       " 'imagines',\n",
       " 'sleepiest',\n",
       " 'shallop',\n",
       " 'hypothesize',\n",
       " 'barnacle',\n",
       " 'slipperiness',\n",
       " 'Morgana',\n",
       " 'lashless',\n",
       " 'scornfully',\n",
       " 'steeds',\n",
       " 'Cold',\n",
       " 'juvenile',\n",
       " 'CRUIZE',\n",
       " 'STICK',\n",
       " 'Erromanggoans',\n",
       " 'arterial',\n",
       " 'entitle',\n",
       " 'atmospheres',\n",
       " 'LUCIAN',\n",
       " 'herded',\n",
       " 'unconsciousness',\n",
       " 'rhyme',\n",
       " 'Ashantee',\n",
       " 'assuaging',\n",
       " 'glade',\n",
       " '144',\n",
       " 'lath',\n",
       " 'departing',\n",
       " 'lording',\n",
       " 'reservoirs',\n",
       " 'underwriter',\n",
       " 'nuptial',\n",
       " 'propelled',\n",
       " 'trampled',\n",
       " 'physiologist',\n",
       " 'Hither',\n",
       " 'maddens',\n",
       " 'glazier',\n",
       " 'Level',\n",
       " 'Cetacea',\n",
       " 'county',\n",
       " 'VESSEL',\n",
       " 'Zealanders',\n",
       " 'Animated',\n",
       " '79',\n",
       " 'unmarred',\n",
       " 'empties',\n",
       " 'warringly',\n",
       " 'Connecticut',\n",
       " 'expediency',\n",
       " 'dough',\n",
       " '150',\n",
       " 'independently',\n",
       " 'interpreted',\n",
       " 'thrills',\n",
       " 'COWLEY',\n",
       " 'Burst',\n",
       " 'ravines',\n",
       " 'corkscrew',\n",
       " 'constituting',\n",
       " 'BOATS',\n",
       " 'merest',\n",
       " '116',\n",
       " 'burghers',\n",
       " 'House',\n",
       " 'outwardly',\n",
       " 'spies',\n",
       " 'PLINY',\n",
       " 'slogan',\n",
       " 'caressed',\n",
       " 'sinks',\n",
       " 'Steel',\n",
       " 'Mealy',\n",
       " 'Cods',\n",
       " 'traditional',\n",
       " 'ramifying',\n",
       " 'Merely',\n",
       " 'bantam',\n",
       " 'bluntly',\n",
       " 'scraggy',\n",
       " 'vicissitude',\n",
       " 'ADVENTURES',\n",
       " 'indomitable',\n",
       " 'thronged',\n",
       " 'cathedral',\n",
       " 'rickety',\n",
       " 'encamped',\n",
       " 'reverenced',\n",
       " 'operating',\n",
       " '67',\n",
       " 'determination',\n",
       " 'gentleness',\n",
       " 'scabbards',\n",
       " 'Potluck',\n",
       " 'emoluments',\n",
       " 'overlording',\n",
       " 'devotees',\n",
       " 'circulate',\n",
       " 'limestone',\n",
       " 'revolutions',\n",
       " 'plazza',\n",
       " 'obstacle',\n",
       " 'terrapin',\n",
       " 'diagonically',\n",
       " 'Paris',\n",
       " 'entertainment',\n",
       " 'Mason',\n",
       " 'Alarmed',\n",
       " 'cymballing',\n",
       " 'CRUISING',\n",
       " 'saddle',\n",
       " 'MOUTH',\n",
       " 'germs',\n",
       " 'states',\n",
       " 'bulbous',\n",
       " 'stupidly',\n",
       " 'IAN',\n",
       " 'provincials',\n",
       " 'beamed',\n",
       " 'unblinkingly',\n",
       " 'Shipped',\n",
       " 'dippers',\n",
       " 'amounts',\n",
       " 'amounted',\n",
       " 'toying',\n",
       " 'Wheelbarrow',\n",
       " 'gambol',\n",
       " 'intertangled',\n",
       " 'capriciously',\n",
       " 'defaced',\n",
       " 'feasting',\n",
       " 'habitudes',\n",
       " 'unaided',\n",
       " 'counties',\n",
       " 'THUS',\n",
       " 'criterion',\n",
       " 'vividly',\n",
       " 'Draws',\n",
       " 'lexicographer',\n",
       " 'monumental',\n",
       " 'friction',\n",
       " 'Edward',\n",
       " 'outblown',\n",
       " 'phrensied',\n",
       " 'bloodiest',\n",
       " 'comely',\n",
       " 'handicrafts',\n",
       " 'shouldering',\n",
       " 'synod',\n",
       " 'Dodge',\n",
       " 'wittiness',\n",
       " 'Simoon',\n",
       " 'Epilogue',\n",
       " 'panels',\n",
       " 'symbolizings',\n",
       " 'icily',\n",
       " '23',\n",
       " 'rifled',\n",
       " 'proffer',\n",
       " 'butteries',\n",
       " 'estate',\n",
       " 'clumsiest',\n",
       " 'crashing',\n",
       " 'Inert',\n",
       " 'BACON',\n",
       " 'goaded',\n",
       " 'lawful',\n",
       " 'disorders',\n",
       " 'voided',\n",
       " 'Quog',\n",
       " 'unfurling',\n",
       " 'aspiring',\n",
       " 'nipper',\n",
       " 'moors',\n",
       " '91',\n",
       " 'leaded',\n",
       " 'circulation',\n",
       " 'seminal',\n",
       " 'consulting',\n",
       " 'Freeze',\n",
       " 'bowstring',\n",
       " 'reverse',\n",
       " 'poop',\n",
       " 'sittin',\n",
       " 'incrustation',\n",
       " 'domineered',\n",
       " 'exhaustive',\n",
       " 'rub',\n",
       " 'Commanders',\n",
       " 'icefield',\n",
       " 'branding',\n",
       " 'thriving',\n",
       " 'substantive',\n",
       " 'puddings',\n",
       " 'gaspings',\n",
       " 'penetrating',\n",
       " 'thrones',\n",
       " 'digester',\n",
       " 'forbid',\n",
       " 'enacted',\n",
       " 'plaguey',\n",
       " 'roly',\n",
       " 'opium',\n",
       " 'Asa',\n",
       " 'verbatim',\n",
       " 'impregnated',\n",
       " 'shipyards',\n",
       " 'prefecture',\n",
       " 'plugged',\n",
       " 'cylindrically',\n",
       " 'expedition',\n",
       " 'phiz',\n",
       " '?--\"',\n",
       " 'panellings',\n",
       " 'PRESSED',\n",
       " 'regardings',\n",
       " 'Gnawed',\n",
       " 'renowned',\n",
       " 'thinness',\n",
       " 'Whitehall',\n",
       " 'marsh',\n",
       " 'Andrew',\n",
       " 'flatly',\n",
       " 'haphazard',\n",
       " 'tablet',\n",
       " 'smallness',\n",
       " 'mysteriously',\n",
       " 'soldier',\n",
       " 'exported',\n",
       " 'Inserting',\n",
       " 'initiated',\n",
       " 'Applied',\n",
       " 'hindmost',\n",
       " 'withdraws',\n",
       " 'Actium',\n",
       " 'reddish',\n",
       " 'solicited',\n",
       " 'drat',\n",
       " 'gouty',\n",
       " 'abatement',\n",
       " 'unanswerable',\n",
       " 'gor',\n",
       " 'placidly',\n",
       " 'loyal',\n",
       " 'upheaving',\n",
       " 'robbers',\n",
       " 'perspectives',\n",
       " 'Cistern',\n",
       " 'OVER',\n",
       " 'hopefulness',\n",
       " 'dwarfed',\n",
       " 'toils',\n",
       " 'rustles',\n",
       " 'obscures',\n",
       " 'inactive',\n",
       " 'Walfish',\n",
       " 'scrambled',\n",
       " 'pyres',\n",
       " 'overture',\n",
       " 'Hoveringly',\n",
       " 'strawberries',\n",
       " 'mature',\n",
       " 'criminal',\n",
       " 'woody',\n",
       " 'unearthed',\n",
       " 'poled',\n",
       " 'Juba',\n",
       " 'Proceed',\n",
       " 'eels',\n",
       " 'dentists',\n",
       " 'duelled',\n",
       " 'eider',\n",
       " 'ebbs',\n",
       " 'h',\n",
       " 'Smells',\n",
       " 'Cambyses',\n",
       " 'neighborhood',\n",
       " 'Constantine',\n",
       " 'knockers',\n",
       " 'Bonneterre',\n",
       " 'Powers',\n",
       " 'courteous',\n",
       " 'SISTER',\n",
       " 'intermixture',\n",
       " 'depressed',\n",
       " 'schoolmasters',\n",
       " 'fervent',\n",
       " 'presentment',\n",
       " 'smacks',\n",
       " 'envoy',\n",
       " 'uncheered',\n",
       " 'Falsehood',\n",
       " 'incarnations',\n",
       " 'jars',\n",
       " 'banner',\n",
       " 'druggs',\n",
       " 'unparticipated',\n",
       " 'subtract',\n",
       " 'unwound',\n",
       " 'Apoplexy',\n",
       " 'comet',\n",
       " 'lately',\n",
       " 'Massacre',\n",
       " 'fairer',\n",
       " 'evinces',\n",
       " 'simplicity',\n",
       " 'shocked',\n",
       " 'prose',\n",
       " 'liturgies',\n",
       " 'Awful',\n",
       " 'cymballed',\n",
       " 'supernaturalism',\n",
       " 'mastodons',\n",
       " 'thimbleful',\n",
       " 'Rabbins',\n",
       " 'ROCKS',\n",
       " 'pinched',\n",
       " 'punctually',\n",
       " 'ROLL',\n",
       " 'Silly',\n",
       " 'SAILORS',\n",
       " 'worryings',\n",
       " 'dwells',\n",
       " 'HEAD',\n",
       " 'summons',\n",
       " 'plans',\n",
       " 'Somehow',\n",
       " 'comply',\n",
       " 'Please',\n",
       " 'felled',\n",
       " '63',\n",
       " 'delegated',\n",
       " 'aleak',\n",
       " 'unfeatured',\n",
       " 'g',\n",
       " 'restore',\n",
       " 'MENDING',\n",
       " 'gamboge',\n",
       " 'clustering',\n",
       " 'Lit',\n",
       " 'Cloud',\n",
       " '127',\n",
       " 'paine',\n",
       " 'blasts',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9002"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist.hapaxes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2   Fine-grained Selection of Words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the long words of a text; perhaps these will be more characteristic and informative. For this we adapt some notation from set theory. We would like to find the words from the vocabulary of the text that are more than 15 characters long. Let's call this property P, so that P(w) is true if and only if w is more than 15 characters long. Now we can express the words of interest using mathematical set notation as shown in (1a). This means \"the set of all w such that w is an element of V (the vocabulary) and w has property P\".\n",
    "\n",
    "(1)\t\n",
    "\n",
    "a.\t\t$$ {w | w ∈ V & P(w)} $$\n",
    "\n",
    "b.\t\t$$ [w\\ for\\ w\\ in\\ V\\ if\\ p(w)] $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding Python expression is given in (1b). (Note that it produces a list, not a set, which means that duplicates are possible.) Observe how similar the two notations are. Let's go one more step and write executable Python code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIRCUMNAVIGATION',\n",
       " 'Physiognomically',\n",
       " 'apprehensiveness',\n",
       " 'cannibalistically',\n",
       " 'characteristically',\n",
       " 'circumnavigating',\n",
       " 'circumnavigation',\n",
       " 'circumnavigations',\n",
       " 'comprehensiveness',\n",
       " 'hermaphroditical',\n",
       " 'indiscriminately',\n",
       " 'indispensableness',\n",
       " 'irresistibleness',\n",
       " 'physiognomically',\n",
       " 'preternaturalness',\n",
       " 'responsibilities',\n",
       " 'simultaneousness',\n",
       " 'subterraneousness',\n",
       " 'supernaturalness',\n",
       " 'superstitiousness',\n",
       " 'uncomfortableness',\n",
       " 'uncompromisedness',\n",
       " 'undiscriminating',\n",
       " 'uninterpenetratingly']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V=set(text1)\n",
    "long_words=[w for w in V if len(w)>15]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word w in the vocabulary V, we check whether len(w) is greater than 15; all other words will be ignored. We will discuss this syntax more carefully later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to our task of finding words that characterize a text. Notice that the long words in text4 reflect its national focus — constitutionally, transcontinental — whereas those in text5 reflect its informal content: boooooooooooglyyyyyy and yuuuuuuuuuuuummmmmmmmmmmm. Have we succeeded in automatically extracting words that typify a text? Well, these very long words are often hapaxes (i.e., unique) and perhaps it would be better to find frequently occurring long words. This seems promising since it eliminates frequent short words (e.g., the) and infrequent long words (e.g. antiphilosophists). Here are all words from the chat corpus that are longer than seven characters, that occur more than seven times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#14-19teens',\n",
       " '#talkcity_adults',\n",
       " '((((((((((',\n",
       " '........',\n",
       " 'Question',\n",
       " 'actually',\n",
       " 'anything',\n",
       " 'computer',\n",
       " 'cute.-ass',\n",
       " 'everyone',\n",
       " 'football',\n",
       " 'innocent',\n",
       " 'listening',\n",
       " 'remember',\n",
       " 'seriously',\n",
       " 'something',\n",
       " 'together',\n",
       " 'tomorrow',\n",
       " 'watching']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist5=FreqDist(text5)\n",
    "sorted(w for w in set(text5) if len(w)>7 and fdist5[w]>7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we have used two conditions: len(w) > 7 ensures that the words are longer than seven letters, and fdist5[w] > 7 ensures that these words occur more than seven times. At last we have managed to automatically identify the frequently-occurring content-bearing words of the text. It is a modest but important milestone: a tiny piece of code, processing tens of thousands of words, produces some informative output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3   Collocations and Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collocation is a sequence of words that occur together unusually often. Thus red wine is a collocation, whereas the wine is not. A characteristic of collocations is that they are resistant to substitution with words that have similar senses; for example, maroon wine sounds definitely odd.\n",
    "\n",
    "To get a handle on collocations, we start off by extracting from a text a list of word pairs, also known as bigrams. This is easily accomplished with the function bigrams():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('more', 'is'), ('is', 'said'), ('said', 'than'), ('than', 'done')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams(['more', 'is', 'said', 'than', 'done']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we see that the pair of words than-done is a bigram, and we write it in Python as ('than', 'done'). Now, collocations are essentially just frequent bigrams, except that we want to pay more attention to the cases that involve rare words. In particular, we want to find bigrams that occur more often than we would expect based on the frequency of the individual words. The collocations() function does this for us. We will see how it works later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would like; medium build; social drinker; quiet nights; non smoker;\n",
      "long term; age open; Would like; easy going; financially secure; fun\n",
      "times; similar interests; Age open; weekends away; poss rship; well\n",
      "presented; never married; single mum; permanent relationship; slim\n",
      "build\n"
     ]
    }
   ],
   "source": [
    "text8.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanna chat; PART JOIN; MODE #14-19teens; JOIN PART; PART PART;\n",
      "cute.-ass MP3; MP3 player; JOIN JOIN; times .. .; ACTION watches; guys\n",
      "wanna; song lasts; last night; ACTION sits; -...)...- S.M.R.; Lime\n",
      "Player; Player 12%; dont know; lez gurls; long time\n"
     ]
    }
   ],
   "source": [
    "text5.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>The collocations that emerge are very specific to the genre of the texts. In order to find red wine as a collocation, we would need to process a much larger body of text.\n",
    "\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4   Counting Other Things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting words is useful, but we can count other things too. For example, we can look at the distribution of word lengths in a text, by creating a FreqDist out of a long list of numbers, where each number is the length of the corresponding word in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19 samples and 260819 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({1: 47933,\n",
       "          2: 38513,\n",
       "          3: 50223,\n",
       "          4: 42345,\n",
       "          5: 26597,\n",
       "          6: 17111,\n",
       "          7: 14399,\n",
       "          8: 9966,\n",
       "          9: 6428,\n",
       "          10: 3528,\n",
       "          11: 1873,\n",
       "          12: 1053,\n",
       "          13: 567,\n",
       "          14: 177,\n",
       "          15: 70,\n",
       "          16: 22,\n",
       "          17: 12,\n",
       "          18: 1,\n",
       "          20: 1})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1=FreqDist(len(w) for w in text1)\n",
    "print(fdist1)\n",
    "fdist1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by deriving a list of the lengths of words in text1 [1], and the FreqDist then counts the number of times each of these occurs [2]. The result [3] is a distribution containing a quarter of a million items, each of which is a number corresponding to a word token in the text. But there are at most only 20 distinct items being counted, the numbers 1 through 20, because there are only 20 different word lengths. I.e., there are words consisting of just one character, two characters, ..., twenty characters, but none with twenty one or more characters. One might wonder how frequent the different lengths of word are (e.g., how many words of length four appear in the text, are there more words of length five than length four, etc). We can do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19255882431878046"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common()\n",
    "fdist1.max()\n",
    "fdist1[3]\n",
    "fdist1.freq(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>From this we see that the most frequent word length is 3, and that words of length 3 account for roughly 50,000 (or 20%) of the words making up the book. Although we will not pursue it here, further analysis of word length might help us understand differences between authors, genres, or languages.\n",
    "\n",
    "</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 summarizes the functions defined in frequency distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](freq.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4   Back to Python: Making Decisions and Taking Control\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](str.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples of these operators being used to select words from our texts: words ending with -ableness; words containing gnt; words having an initial capital; and words consisting entirely of digits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comfortableness',\n",
       " 'honourableness',\n",
       " 'immutableness',\n",
       " 'indispensableness',\n",
       " 'indomitableness',\n",
       " 'intolerableness',\n",
       " 'palpableness',\n",
       " 'reasonableness',\n",
       " 'uncomfortableness']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text1) if w.endswith('ableness'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sovereignty', 'sovereignties', 'sovereignty']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(term for term in set(text4) if 'gnt' in term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Aaaaaaaaah',\n",
       " 'Aaaaaaaah',\n",
       " 'Aaaaaah',\n",
       " 'Aaaah',\n",
       " 'Aaaaugh',\n",
       " 'Aaagh',\n",
       " 'Aaah',\n",
       " 'Aaauggh',\n",
       " 'Aaaugh',\n",
       " 'Aaauugh',\n",
       " 'Aagh',\n",
       " 'Aah',\n",
       " 'Aauuggghhh',\n",
       " 'Aauuugh',\n",
       " 'Aauuuuugh',\n",
       " 'Aauuuves',\n",
       " 'Action',\n",
       " 'Actually',\n",
       " 'African',\n",
       " 'Ages',\n",
       " 'Aggh',\n",
       " 'Agh',\n",
       " 'Ah',\n",
       " 'Ahh',\n",
       " 'Alice',\n",
       " 'All',\n",
       " 'Allo',\n",
       " 'Almighty',\n",
       " 'Alright',\n",
       " 'Am',\n",
       " 'Amen',\n",
       " 'An',\n",
       " 'Anarcho',\n",
       " 'And',\n",
       " 'Angnor',\n",
       " 'Anthrax',\n",
       " 'Antioch',\n",
       " 'Anybody',\n",
       " 'Anyway',\n",
       " 'Apples',\n",
       " 'Aramaic',\n",
       " 'Are',\n",
       " 'Arimathea',\n",
       " 'Armaments',\n",
       " 'Arthur',\n",
       " 'As',\n",
       " 'Ask',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Attila',\n",
       " 'Augh',\n",
       " 'Autumn',\n",
       " 'Auuuuuuuugh',\n",
       " 'Away',\n",
       " 'Ay',\n",
       " 'Ayy',\n",
       " 'B',\n",
       " 'Back',\n",
       " 'Bad',\n",
       " 'Badon',\n",
       " 'Battle',\n",
       " 'Be',\n",
       " 'Beast',\n",
       " 'Bedevere',\n",
       " 'Bedwere',\n",
       " 'Behold',\n",
       " 'Between',\n",
       " 'Beyond',\n",
       " 'Black',\n",
       " 'Bloody',\n",
       " 'Blue',\n",
       " 'Bon',\n",
       " 'Bones',\n",
       " 'Book',\n",
       " 'Bors',\n",
       " 'Brave',\n",
       " 'Bravely',\n",
       " 'Bravest',\n",
       " 'Bread',\n",
       " 'Bridge',\n",
       " 'Bring',\n",
       " 'Bristol',\n",
       " 'Britain',\n",
       " 'Britons',\n",
       " 'Brother',\n",
       " 'Build',\n",
       " 'Burn',\n",
       " 'But',\n",
       " 'By',\n",
       " 'C',\n",
       " 'Caerbannog',\n",
       " 'Camaaaaaargue',\n",
       " 'Camelot',\n",
       " 'Castle',\n",
       " 'Chapter',\n",
       " 'Charge',\n",
       " 'Chaste',\n",
       " 'Cherries',\n",
       " 'Chicken',\n",
       " 'Chickennn',\n",
       " 'Chop',\n",
       " 'Christ',\n",
       " 'Churches',\n",
       " 'Cider',\n",
       " 'Clark',\n",
       " 'Clear',\n",
       " 'Come',\n",
       " 'Concorde',\n",
       " 'Consult',\n",
       " 'Cornwall',\n",
       " 'Could',\n",
       " 'Course',\n",
       " 'Court',\n",
       " 'Crapper',\n",
       " 'Cut',\n",
       " 'Dappy',\n",
       " 'Death',\n",
       " 'Defeat',\n",
       " 'Dennis',\n",
       " 'Did',\n",
       " 'Didn',\n",
       " 'Dingo',\n",
       " 'Dis',\n",
       " 'Divine',\n",
       " 'Do',\n",
       " 'Doctor',\n",
       " 'Does',\n",
       " 'Don',\n",
       " 'Dragon',\n",
       " 'Dramatically',\n",
       " 'Ecky',\n",
       " 'Ector',\n",
       " 'Eee',\n",
       " 'Eh',\n",
       " 'Enchanter',\n",
       " 'England',\n",
       " 'English',\n",
       " 'Erbert',\n",
       " 'Ere',\n",
       " 'Erm',\n",
       " 'Eternal',\n",
       " 'European',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Everything',\n",
       " 'Ewing',\n",
       " 'Exactly',\n",
       " 'Excalibur',\n",
       " 'Excuse',\n",
       " 'Explain',\n",
       " 'Far',\n",
       " 'Farewell',\n",
       " 'Father',\n",
       " 'Fetchez',\n",
       " 'Fiends',\n",
       " 'Fine',\n",
       " 'First',\n",
       " 'Firstly',\n",
       " 'Five',\n",
       " 'Follow',\n",
       " 'For',\n",
       " 'Forgive',\n",
       " 'Forward',\n",
       " 'Found',\n",
       " 'Four',\n",
       " 'France',\n",
       " 'Frank',\n",
       " 'French',\n",
       " 'Gable',\n",
       " 'Galahad',\n",
       " 'Gallahad',\n",
       " 'Gawain',\n",
       " 'Get',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Good',\n",
       " 'Gorge',\n",
       " 'Grail',\n",
       " 'Great',\n",
       " 'Greetings',\n",
       " 'Grenade',\n",
       " 'Guards',\n",
       " 'Guy',\n",
       " 'Ha',\n",
       " 'Hah',\n",
       " 'Hallo',\n",
       " 'Halt',\n",
       " 'Hand',\n",
       " 'Hang',\n",
       " 'Have',\n",
       " 'Haw',\n",
       " 'He',\n",
       " 'Hee',\n",
       " 'Heee',\n",
       " 'Heh',\n",
       " 'Hello',\n",
       " 'Help',\n",
       " 'Herbert',\n",
       " 'Here',\n",
       " 'Hey',\n",
       " 'Hic',\n",
       " 'Hill',\n",
       " 'Himself',\n",
       " 'His',\n",
       " 'Hiyaah',\n",
       " 'Hiyah',\n",
       " 'Hiyya',\n",
       " 'Hm',\n",
       " 'Hmm',\n",
       " 'Ho',\n",
       " 'Hoa',\n",
       " 'Hold',\n",
       " 'Holy',\n",
       " 'Honestly',\n",
       " 'Hoo',\n",
       " 'Hooray',\n",
       " 'How',\n",
       " 'Huh',\n",
       " 'Hurry',\n",
       " 'Huy',\n",
       " 'Huyah',\n",
       " 'Hya',\n",
       " 'Hyy',\n",
       " 'I',\n",
       " 'Idiom',\n",
       " 'Iesu',\n",
       " 'If',\n",
       " 'Iiiiives',\n",
       " 'Iiiives',\n",
       " 'In',\n",
       " 'Is',\n",
       " 'Isn',\n",
       " 'It',\n",
       " 'Ives',\n",
       " 'Jesus',\n",
       " 'Joseph',\n",
       " 'Just',\n",
       " 'Keep',\n",
       " 'King',\n",
       " 'Knight',\n",
       " 'Knights',\n",
       " 'Lady',\n",
       " 'Lake',\n",
       " 'Lancelot',\n",
       " 'Launcelot',\n",
       " 'Lead',\n",
       " 'Leaving',\n",
       " 'Let',\n",
       " 'Lie',\n",
       " 'Like',\n",
       " 'Listen',\n",
       " 'Loimbard',\n",
       " 'Look',\n",
       " 'Looks',\n",
       " 'Lord',\n",
       " 'Lucky',\n",
       " 'Make',\n",
       " 'Man',\n",
       " 'May',\n",
       " 'Maynard',\n",
       " 'Meanwhile',\n",
       " 'Mercea',\n",
       " 'Message',\n",
       " 'Midget',\n",
       " 'Mind',\n",
       " 'Mine',\n",
       " 'Mmm',\n",
       " 'Monsieur',\n",
       " 'More',\n",
       " 'Morning',\n",
       " 'Most',\n",
       " 'Mother',\n",
       " 'Mud',\n",
       " 'Must',\n",
       " 'My',\n",
       " 'N',\n",
       " 'Nador',\n",
       " 'Nay',\n",
       " 'Neee',\n",
       " 'Never',\n",
       " 'Ni',\n",
       " 'Nine',\n",
       " 'Ninepence',\n",
       " 'No',\n",
       " 'None',\n",
       " 'Not',\n",
       " 'Nothing',\n",
       " 'Now',\n",
       " 'Nu',\n",
       " 'O',\n",
       " 'Of',\n",
       " 'Off',\n",
       " 'Oh',\n",
       " 'Ohh',\n",
       " 'Old',\n",
       " 'Olfin',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'One',\n",
       " 'Ooh',\n",
       " 'Oooh',\n",
       " 'Oooo',\n",
       " 'Oooohoohohooo',\n",
       " 'Oooooooh',\n",
       " 'Open',\n",
       " 'Or',\n",
       " 'Order',\n",
       " 'Other',\n",
       " 'Oui',\n",
       " 'Our',\n",
       " 'Over',\n",
       " 'Ow',\n",
       " 'Packing',\n",
       " 'Patsy',\n",
       " 'Pendragon',\n",
       " 'Peng',\n",
       " 'Perhaps',\n",
       " 'Peril',\n",
       " 'Picture',\n",
       " 'Pie',\n",
       " 'Piglet',\n",
       " 'Pin',\n",
       " 'Please',\n",
       " 'Practice',\n",
       " 'Prepare',\n",
       " 'Prince',\n",
       " 'Princess',\n",
       " 'Providence',\n",
       " 'Psalms',\n",
       " 'Pull',\n",
       " 'Pure',\n",
       " 'Put',\n",
       " 'Quick',\n",
       " 'Quickly',\n",
       " 'Quiet',\n",
       " 'Quite',\n",
       " 'Quoi',\n",
       " 'Rather',\n",
       " 'Really',\n",
       " 'Recently',\n",
       " 'Remove',\n",
       " 'Rheged',\n",
       " 'Ridden',\n",
       " 'Right',\n",
       " 'Riiight',\n",
       " 'Robin',\n",
       " 'Robinson',\n",
       " 'Roger',\n",
       " 'Round',\n",
       " 'Run',\n",
       " 'Running',\n",
       " 'S',\n",
       " 'Said',\n",
       " 'Saint',\n",
       " 'Saxons',\n",
       " 'Say',\n",
       " 'Schools',\n",
       " 'See',\n",
       " 'Seek',\n",
       " 'Shall',\n",
       " 'She',\n",
       " 'Shh',\n",
       " 'Shrubber',\n",
       " 'Shrubberies',\n",
       " 'Shut',\n",
       " 'Silence',\n",
       " 'Silly',\n",
       " 'Since',\n",
       " 'Sir',\n",
       " 'Skip',\n",
       " 'So',\n",
       " 'Sorry',\n",
       " 'Speak',\n",
       " 'Splendid',\n",
       " 'Spring',\n",
       " 'Stand',\n",
       " 'Stay',\n",
       " 'Steady',\n",
       " 'Stop',\n",
       " 'Summer',\n",
       " 'Supposing',\n",
       " 'Supreme',\n",
       " 'Surely',\n",
       " 'Swamp',\n",
       " 'Table',\n",
       " 'Tale',\n",
       " 'Tall',\n",
       " 'Tell',\n",
       " 'Thank',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Thee',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Thou',\n",
       " 'Thpppppt',\n",
       " 'Thppppt',\n",
       " 'Thpppt',\n",
       " 'Thppt',\n",
       " 'Three',\n",
       " 'Throw',\n",
       " 'Thsss',\n",
       " 'Thursday',\n",
       " 'Thy',\n",
       " 'Til',\n",
       " 'Tim',\n",
       " 'Tis',\n",
       " 'To',\n",
       " 'Today',\n",
       " 'Together',\n",
       " 'Too',\n",
       " 'Torment',\n",
       " 'Tower',\n",
       " 'True',\n",
       " 'Try',\n",
       " 'Twenty',\n",
       " 'Two',\n",
       " 'U',\n",
       " 'Uh',\n",
       " 'Uhh',\n",
       " 'Ulk',\n",
       " 'Um',\n",
       " 'Umhm',\n",
       " 'Umm',\n",
       " 'Un',\n",
       " 'Unfortunately',\n",
       " 'Until',\n",
       " 'Use',\n",
       " 'Uther',\n",
       " 'Uugh',\n",
       " 'Uuh',\n",
       " 'Very',\n",
       " 'Victory',\n",
       " 'W',\n",
       " 'Waa',\n",
       " 'Wait',\n",
       " 'Walk',\n",
       " 'Wayy',\n",
       " 'We',\n",
       " 'Welcome',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Where',\n",
       " 'Which',\n",
       " 'Who',\n",
       " 'Whoa',\n",
       " 'Why',\n",
       " 'Will',\n",
       " 'Winston',\n",
       " 'Winter',\n",
       " 'With',\n",
       " 'Woa',\n",
       " 'Wood',\n",
       " 'Would',\n",
       " 'Y',\n",
       " 'Yapping',\n",
       " 'Yay',\n",
       " 'Yeaaah',\n",
       " 'Yeaah',\n",
       " 'Yeah',\n",
       " 'Yes',\n",
       " 'You',\n",
       " 'Your',\n",
       " 'Yup',\n",
       " 'Zoot']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(text6) if item.istitle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '61']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.isdigit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create more complex conditions. If c is a condition, then not c is also a condition. If we have two conditions c1 and c2, then we can combine them to form a new condition using conjunction and disjunction: c1 and c2, c1 or c2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>\n",
    "\n",
    "<b>Your</b> Turn: Run the following examples and try to explain what is going on in each one. Next, try to make up some conditions of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock-index',\n",
       " 'index-arbitrage',\n",
       " 'index-fund',\n",
       " 'index-options',\n",
       " 'index-related',\n",
       " 'stock-index']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text7) if '-' in w and 'index' in w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abelmizraim',\n",
       " 'Allonbachuth',\n",
       " 'Beerlahairoi',\n",
       " 'Canaanitish',\n",
       " 'Chedorlaomer',\n",
       " 'Girgashites',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Ishmeelites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Kirjatharba',\n",
       " 'Melchizedek',\n",
       " 'Mesopotamia',\n",
       " 'Peradventure',\n",
       " 'Philistines',\n",
       " 'Zaphnathpaaneah']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wd for wd in set(text3) if wd.istitle() and len(wd) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', '29', '61', 'Nov.', 'Pierre', 'Vinken']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(sent7) if not  w.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ancient',\n",
       " 'ceiling',\n",
       " 'conceit',\n",
       " 'conceited',\n",
       " 'conceive',\n",
       " 'conscience',\n",
       " 'conscientious',\n",
       " 'conscientiously',\n",
       " 'deceitful',\n",
       " 'deceive',\n",
       " 'deceived',\n",
       " 'deceiving',\n",
       " 'deficiencies',\n",
       " 'deficiency',\n",
       " 'deficient',\n",
       " 'delicacies',\n",
       " 'excellencies',\n",
       " 'fancied',\n",
       " 'insufficiency',\n",
       " 'insufficient',\n",
       " 'legacies',\n",
       " 'perceive',\n",
       " 'perceived',\n",
       " 'perceiving',\n",
       " 'prescience',\n",
       " 'prophecies',\n",
       " 'receipt',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'receiving',\n",
       " 'society',\n",
       " 'species',\n",
       " 'sufficient',\n",
       " 'sufficiently',\n",
       " 'undeceive',\n",
       " 'undeceiving']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t for t in set(text2) if 'cie' in t or 'cei' in t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2   Operating on Every Element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 3, we saw some examples of counting items other than words. Let's take a closer look at the notation we used:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CALL', 'ME', 'ISHMAEL', '.', 'SOME']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1]\n",
    "[w.upper() for w in sent1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>\n",
    "\n",
    "The notation just described is called a \"list comprehension.\" This is our first example of a Python idiom, a fixed notation that we use habitually without bothering to analyze each time. Mastering such idioms is an important part of becoming a fluent Python programmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return to the question of vocabulary size, and apply the same idiom here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260819, 19317, 17231)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1), len(set(text1)), len(set(w.lower() for w in text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are not double-counting words like This and this, which differ only in capitalization, we've wiped 2,000 off the vocabulary count! We can go a step further and eliminate numbers and punctuation from the vocabulary count by filtering out any non-alphabetic items:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16948, 17231)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(w.lower() for w in text1 if w.isalpha())), len(set(w.lower() for w in text1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is slightly complicated: it lowercases all the purely alphabetic items. Perhaps it would have been simpler just to count the lowercase-only items, but this gives the wrong answer (why?).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'navigator',\n",
       " 'kedron',\n",
       " 'comfortableness',\n",
       " 'legislators',\n",
       " 'assurance',\n",
       " 'despite',\n",
       " 'announced',\n",
       " 'determining',\n",
       " 'stumbling',\n",
       " 'spermy',\n",
       " 'mow',\n",
       " 'quakerish',\n",
       " 'recover',\n",
       " 'rigorous',\n",
       " 'loam',\n",
       " 'pinny',\n",
       " 'bartholomew',\n",
       " 'uneventfulness',\n",
       " 'headlands',\n",
       " 'guess',\n",
       " 'stroll',\n",
       " 'destruction',\n",
       " 'iron',\n",
       " 'ached',\n",
       " 'enderbys',\n",
       " 'dainty',\n",
       " 'sourceless',\n",
       " 'farthing',\n",
       " 'inequality',\n",
       " 'woodlands',\n",
       " 'moderns',\n",
       " 'cost',\n",
       " 'expanded',\n",
       " 'sights',\n",
       " 'illimitably',\n",
       " 'drowsy',\n",
       " 'holdest',\n",
       " 'throwing',\n",
       " 'sane',\n",
       " 'woo',\n",
       " 'brag',\n",
       " 'basis',\n",
       " 'unload',\n",
       " 'vexatious',\n",
       " 'fata',\n",
       " 'shabbily',\n",
       " 'orisons',\n",
       " 'innumerable',\n",
       " 'buoyant',\n",
       " 'zogranda',\n",
       " 'truest',\n",
       " 'pursuit',\n",
       " 'carlines',\n",
       " 'selectest',\n",
       " 'asked',\n",
       " 'lithe',\n",
       " 'crave',\n",
       " 'counsels',\n",
       " 'plying',\n",
       " 'eulogy',\n",
       " 'boarded',\n",
       " 'passage',\n",
       " 'divorced',\n",
       " 'lowly',\n",
       " 'summary',\n",
       " 'stamped',\n",
       " 'lounging',\n",
       " 'scooped',\n",
       " 'rendered',\n",
       " 'oxen',\n",
       " 'relent',\n",
       " 'punish',\n",
       " 'mutineers',\n",
       " 'mistaken',\n",
       " 'neighbors',\n",
       " 'bashful',\n",
       " 'recoil',\n",
       " 'distant',\n",
       " 'chili',\n",
       " 'induce',\n",
       " 'languishing',\n",
       " 'sunken',\n",
       " 'faithful',\n",
       " 'subordinate',\n",
       " 'veracious',\n",
       " 'quilted',\n",
       " 'pisces',\n",
       " 'stranger',\n",
       " 'siamese',\n",
       " 'whistling',\n",
       " 'tying',\n",
       " 'deserted',\n",
       " 'shrink',\n",
       " 'whirls',\n",
       " 'exist',\n",
       " 'entreat',\n",
       " 'alleghanies',\n",
       " 'gluepots',\n",
       " 'up',\n",
       " 'princes',\n",
       " 'salutes',\n",
       " 'brisson',\n",
       " 'slided',\n",
       " 'cupidity',\n",
       " 'thither',\n",
       " 'within',\n",
       " 'ibis',\n",
       " 'alewives',\n",
       " 'displays',\n",
       " 'mathematics',\n",
       " 'hollowing',\n",
       " 'proverbial',\n",
       " 'spilled',\n",
       " 'pulpit',\n",
       " 'carcass',\n",
       " 'sustain',\n",
       " 'tension',\n",
       " 'sheeted',\n",
       " 'render',\n",
       " 'anchors',\n",
       " 'nosegays',\n",
       " 'rockets',\n",
       " 'insured',\n",
       " 'unequal',\n",
       " 'fingers',\n",
       " 'clove',\n",
       " 'obeying',\n",
       " 'methods',\n",
       " 'fat',\n",
       " 'unbuckling',\n",
       " 'entrapped',\n",
       " 'threepence',\n",
       " 'packed',\n",
       " 'brahmins',\n",
       " 'striding',\n",
       " 'mammis',\n",
       " 'venture',\n",
       " 'arches',\n",
       " 'demselves',\n",
       " 'sugary',\n",
       " 'keeper',\n",
       " 'clamber',\n",
       " 'bye',\n",
       " 'music',\n",
       " 'belonged',\n",
       " 'hospitalities',\n",
       " 'signing',\n",
       " 'considerations',\n",
       " 'diffused',\n",
       " 'canopy',\n",
       " 'creatures',\n",
       " 'shelves',\n",
       " 'string',\n",
       " 'triumphant',\n",
       " 'proportion',\n",
       " 'dedication',\n",
       " 'impressed',\n",
       " 'stooped',\n",
       " 'bouton',\n",
       " 'sack',\n",
       " 'wintry',\n",
       " 'cranial',\n",
       " 'poser',\n",
       " 'babbling',\n",
       " 'israel',\n",
       " 'narrow',\n",
       " 'reprimand',\n",
       " 'frost',\n",
       " 'producing',\n",
       " 'quill',\n",
       " 'hooked',\n",
       " 'wrecked',\n",
       " 'fossils',\n",
       " 'uncontinented',\n",
       " 'fed',\n",
       " 'brawny',\n",
       " 'attitudes',\n",
       " 'gorge',\n",
       " 'lot',\n",
       " 'thin',\n",
       " 'renounced',\n",
       " 'boatswain',\n",
       " 'totality',\n",
       " 'apricot',\n",
       " 'pontoppodan',\n",
       " 'territories',\n",
       " 'purr',\n",
       " 'supper',\n",
       " 'nondescript',\n",
       " 'acuteness',\n",
       " '128',\n",
       " 'lamentable',\n",
       " 'scalding',\n",
       " 'keenly',\n",
       " 'page',\n",
       " 'hedgehog',\n",
       " 'magnifying',\n",
       " 'hems',\n",
       " 'choking',\n",
       " 'attribute',\n",
       " 'religious',\n",
       " 'curb',\n",
       " 'freshened',\n",
       " 'caesarian',\n",
       " 'colt',\n",
       " 'legerdemain',\n",
       " 'wellington',\n",
       " 'drive',\n",
       " 'quaff',\n",
       " 'crannies',\n",
       " 'stuffed',\n",
       " 'feather',\n",
       " 'whitenesses',\n",
       " 'shortened',\n",
       " 'heeding',\n",
       " 'determine',\n",
       " 'fuel',\n",
       " 'murmured',\n",
       " 'burgher',\n",
       " 'scornfully',\n",
       " 'passion',\n",
       " 'proprietors',\n",
       " 'rokovoko',\n",
       " 'wampum',\n",
       " 'departure',\n",
       " 'unceremoniously',\n",
       " 'diminish',\n",
       " 'denoted',\n",
       " 'fabled',\n",
       " 'olive',\n",
       " 'aldrovandi',\n",
       " 'crete',\n",
       " 'fours',\n",
       " 'warringly',\n",
       " 'frenzies',\n",
       " 'relics',\n",
       " '150',\n",
       " 'months',\n",
       " 'vigorous',\n",
       " 'jumped',\n",
       " 'xxxix',\n",
       " 'contents',\n",
       " 'unbounded',\n",
       " 'lazarus',\n",
       " 'specimen',\n",
       " 'sharpening',\n",
       " 'weighed',\n",
       " 'traditional',\n",
       " 'echoes',\n",
       " 'comparatively',\n",
       " 'unwinding',\n",
       " 'contended',\n",
       " 'devotees',\n",
       " 'lionel',\n",
       " 'reputation',\n",
       " 'terrapin',\n",
       " 'hag',\n",
       " 'heard',\n",
       " 'sideboard',\n",
       " 'vouchers',\n",
       " 'bulbous',\n",
       " 'fetch',\n",
       " 'tyerman',\n",
       " 'salem',\n",
       " 'net',\n",
       " 'brace',\n",
       " 'daft',\n",
       " 'wish',\n",
       " 'lain',\n",
       " 'prepared',\n",
       " 'aspirations',\n",
       " 'experiments',\n",
       " 'pursed',\n",
       " 'emperors',\n",
       " 'impart',\n",
       " 'retired',\n",
       " '23',\n",
       " 'livelihood',\n",
       " 'dunkirk',\n",
       " 'ruling',\n",
       " 'spiralizations',\n",
       " 'imperative',\n",
       " 'gentlemen',\n",
       " 'regard',\n",
       " 'poop',\n",
       " 'anticipated',\n",
       " 'raved',\n",
       " '79',\n",
       " 'defiles',\n",
       " 'reads',\n",
       " 'thrown',\n",
       " 'spectacle',\n",
       " 'bilocular',\n",
       " 'vivacious',\n",
       " 'unwaning',\n",
       " 'withdrawing',\n",
       " 'purposeless',\n",
       " 'zag',\n",
       " 'fastener',\n",
       " 'bowing',\n",
       " 'respects',\n",
       " 'masts',\n",
       " 'paley',\n",
       " 'amend',\n",
       " 'withal',\n",
       " 'x',\n",
       " 'abraham',\n",
       " 'cream',\n",
       " 'insert',\n",
       " 'rustles',\n",
       " 'counsel',\n",
       " 'singing',\n",
       " 'pyres',\n",
       " 'palisades',\n",
       " 'dragged',\n",
       " 'mature',\n",
       " 'creagh',\n",
       " 'abating',\n",
       " 'angularly',\n",
       " 'boxes',\n",
       " 'incarnations',\n",
       " 'asa',\n",
       " 'rising',\n",
       " 'perpetuates',\n",
       " 'puffing',\n",
       " 'toiled',\n",
       " 'eagle',\n",
       " 'stowaways',\n",
       " 'gloriously',\n",
       " 'object',\n",
       " 'dwells',\n",
       " 'breezelessness',\n",
       " 'medals',\n",
       " 'remnants',\n",
       " 'buoyancy',\n",
       " 'practices',\n",
       " 'proverbially',\n",
       " 'thinkest',\n",
       " 'stifling',\n",
       " 'prejudices',\n",
       " 'instant',\n",
       " 'overmanned',\n",
       " 'wharves',\n",
       " 'merely',\n",
       " 'studying',\n",
       " 'sinewing',\n",
       " 'smooth',\n",
       " 'dash',\n",
       " 'perpendicularly',\n",
       " 'sigh',\n",
       " 'ensue',\n",
       " 'bud',\n",
       " 'thirteen',\n",
       " 'difficulties',\n",
       " 'oarsman',\n",
       " 'mountaineers',\n",
       " 'alluring',\n",
       " 'provincial',\n",
       " 'axles',\n",
       " 'odds',\n",
       " 'wires',\n",
       " 'hall',\n",
       " 'waterproof',\n",
       " 'smite',\n",
       " 'mumbling',\n",
       " 'expressions',\n",
       " '89',\n",
       " 'revealed',\n",
       " 'helmsman',\n",
       " 'habituated',\n",
       " 'light',\n",
       " 'prodigy',\n",
       " 'devoting',\n",
       " 'makest',\n",
       " 'cruising',\n",
       " 'chowders',\n",
       " 'ing',\n",
       " 'extended',\n",
       " 'bitts',\n",
       " 'attitude',\n",
       " 'io',\n",
       " 'seductive',\n",
       " 'disclosures',\n",
       " 'trades',\n",
       " 'doubloons',\n",
       " 'commonplaces',\n",
       " 'comforted',\n",
       " 'tusked',\n",
       " 'perfected',\n",
       " 'island',\n",
       " 'pent',\n",
       " 'shortness',\n",
       " 'lege',\n",
       " 'lengthen',\n",
       " 'phantom',\n",
       " 'piggin',\n",
       " 'pastiles',\n",
       " 'foreboding',\n",
       " 'glim',\n",
       " 'perry',\n",
       " 'countrymen',\n",
       " 'drinking',\n",
       " 'altered',\n",
       " 'lonesomeness',\n",
       " 'acknowledges',\n",
       " 'incognita',\n",
       " 'obscurely',\n",
       " 'insure',\n",
       " 'extravaganzas',\n",
       " 'plaintiveness',\n",
       " 'cones',\n",
       " 'ostentatious',\n",
       " 'avenues',\n",
       " 'symmetry',\n",
       " 'plaything',\n",
       " 'invaluable',\n",
       " 'romantic',\n",
       " 'frighten',\n",
       " 'lastly',\n",
       " 'suburban',\n",
       " 'unpainted',\n",
       " 'throttled',\n",
       " 'er',\n",
       " 'slaughtered',\n",
       " 'clamorous',\n",
       " 'semblance',\n",
       " 'sudden',\n",
       " 'soar',\n",
       " 'hurried',\n",
       " 'consort',\n",
       " 'cleats',\n",
       " 'fitted',\n",
       " 'stuck',\n",
       " 'gaffman',\n",
       " 'demigod',\n",
       " 'feathers',\n",
       " 'parti',\n",
       " 'hist',\n",
       " 'customs',\n",
       " 'cods',\n",
       " 'edge',\n",
       " 'canterbury',\n",
       " 'suspects',\n",
       " 'screen',\n",
       " 'cranes',\n",
       " 'odor',\n",
       " 'funereal',\n",
       " 'frigates',\n",
       " 'repulses',\n",
       " 'openmouthed',\n",
       " 'hams',\n",
       " 'teetering',\n",
       " 'jewelled',\n",
       " 'loftiest',\n",
       " 'oaths',\n",
       " 'girls',\n",
       " 'pistol',\n",
       " 'sunbeam',\n",
       " 'hats',\n",
       " 'cycloid',\n",
       " 'miserly',\n",
       " 'callest',\n",
       " 'despairing',\n",
       " 'deficiency',\n",
       " 'spool',\n",
       " 'gallons',\n",
       " 'allegorical',\n",
       " 'stiffening',\n",
       " 'fowls',\n",
       " 'dandy',\n",
       " 'america',\n",
       " 'prelusive',\n",
       " 'trick',\n",
       " 'they',\n",
       " 'gored',\n",
       " 'grew',\n",
       " 'whosoever',\n",
       " 'trampled',\n",
       " 'traps',\n",
       " 'buoyantly',\n",
       " 'calculated',\n",
       " 'inner',\n",
       " 'fleeces',\n",
       " 'ruthless',\n",
       " 'itch',\n",
       " 'vacant',\n",
       " 'veins',\n",
       " 'musk',\n",
       " 'magical',\n",
       " 'bashaw',\n",
       " 'fragmentary',\n",
       " 'renegades',\n",
       " 'caking',\n",
       " 'who',\n",
       " 'boats',\n",
       " 'passed',\n",
       " 'map',\n",
       " 'wandering',\n",
       " 'practically',\n",
       " 'disport',\n",
       " 'slily',\n",
       " 'cinders',\n",
       " 'majesty',\n",
       " 'tandem',\n",
       " 'donned',\n",
       " 'unsolved',\n",
       " 'stream',\n",
       " 'willed',\n",
       " 'gather',\n",
       " 'juicy',\n",
       " 'intermediate',\n",
       " 'prick',\n",
       " 'plaguy',\n",
       " 'odoriferous',\n",
       " 'pitchpoler',\n",
       " 'merrily',\n",
       " 'coasting',\n",
       " 'much',\n",
       " ';\"',\n",
       " 'apology',\n",
       " 'hoofs',\n",
       " 'unrestingly',\n",
       " 'saratoga',\n",
       " 'villa',\n",
       " 'sartainty',\n",
       " 'chronicler',\n",
       " 'snodhead',\n",
       " 'dint',\n",
       " 'flowed',\n",
       " 'clasped',\n",
       " 'blankets',\n",
       " 'apparatus',\n",
       " 'equity',\n",
       " 'exceedingly',\n",
       " 'extra',\n",
       " 'wing',\n",
       " 'formless',\n",
       " 'ulcerous',\n",
       " 'crockett',\n",
       " 'speeding',\n",
       " 'tie',\n",
       " '1793',\n",
       " 'sell',\n",
       " 'magniloquent',\n",
       " 'blurred',\n",
       " 'versa',\n",
       " 'niger',\n",
       " 'abreast',\n",
       " 'meanings',\n",
       " 'arose',\n",
       " 'savoury',\n",
       " 'leap',\n",
       " 'texture',\n",
       " 'wreck',\n",
       " 'pie',\n",
       " 'males',\n",
       " 'seignories',\n",
       " 'evolutions',\n",
       " 'inducements',\n",
       " 'timid',\n",
       " 'condemning',\n",
       " 'include',\n",
       " 'protested',\n",
       " 'mannikin',\n",
       " 'physiognomical',\n",
       " 'apparently',\n",
       " 'cupola',\n",
       " 'slaughter',\n",
       " 'secret',\n",
       " 'lotus',\n",
       " 'rips',\n",
       " 'model',\n",
       " 'playfully',\n",
       " 'edged',\n",
       " 'lunging',\n",
       " 'fear',\n",
       " 'unappalled',\n",
       " 'surpass',\n",
       " 'professors',\n",
       " 'discolour',\n",
       " 'visit',\n",
       " 'gallantry',\n",
       " 'sleet',\n",
       " 'scarf',\n",
       " 'pulverize',\n",
       " 'plugged',\n",
       " 'infiltrated',\n",
       " 'respiration',\n",
       " 'apoplexy',\n",
       " 'predecessor',\n",
       " 'indubitably',\n",
       " 'shaped',\n",
       " 'bundles',\n",
       " 'sabbath',\n",
       " 'gnashing',\n",
       " 'j',\n",
       " 'inlayings',\n",
       " 'dashes',\n",
       " 'aboriginalness',\n",
       " 'scattered',\n",
       " 'heavy',\n",
       " 'tashtego',\n",
       " 'beseech',\n",
       " 'catastrophe',\n",
       " 'trample',\n",
       " 'mentioned',\n",
       " 'features',\n",
       " 'tahitan',\n",
       " 'oath',\n",
       " 'group',\n",
       " 'difference',\n",
       " 'tragedy',\n",
       " 'rural',\n",
       " 'indispensableness',\n",
       " 'chaldee',\n",
       " 'feeling',\n",
       " 'parm',\n",
       " 'masks',\n",
       " 'thunder',\n",
       " 'sanity',\n",
       " 'vomited',\n",
       " 'noiselessly',\n",
       " 'planet',\n",
       " 'porpoise',\n",
       " 'exacted',\n",
       " 'innocence',\n",
       " 'elbow',\n",
       " 'bowie',\n",
       " 'furnaces',\n",
       " 'holiest',\n",
       " 'pronounced',\n",
       " 'cetology',\n",
       " 'jig',\n",
       " '62',\n",
       " 'hearken',\n",
       " 'alternating',\n",
       " 'voyage',\n",
       " 'ermine',\n",
       " 'supreme',\n",
       " 'similitude',\n",
       " 'indite',\n",
       " 'repair',\n",
       " 'weapon',\n",
       " 'peddlin',\n",
       " 'gurgling',\n",
       " 'disastrous',\n",
       " 'chipped',\n",
       " \"',--\",\n",
       " 'spaniards',\n",
       " 'cables',\n",
       " 'binder',\n",
       " 'proceeds',\n",
       " 'braces',\n",
       " 'keenest',\n",
       " 'beech',\n",
       " 'immersed',\n",
       " 'blanco',\n",
       " 'toilings',\n",
       " 'southwards',\n",
       " 'splashing',\n",
       " 'winking',\n",
       " 'sinful',\n",
       " 'kingly',\n",
       " 'allies',\n",
       " 'howdah',\n",
       " 'combing',\n",
       " 'reverie',\n",
       " 'outdone',\n",
       " 'unmethodically',\n",
       " 'kin',\n",
       " 'strings',\n",
       " 'revolves',\n",
       " 'spars',\n",
       " 'genteel',\n",
       " 'birth',\n",
       " 'nailed',\n",
       " 'sits',\n",
       " 'mannerly',\n",
       " 'holier',\n",
       " 'orphan',\n",
       " 'fronting',\n",
       " 'viol',\n",
       " 'robbed',\n",
       " 'annihilating',\n",
       " 'counterpart',\n",
       " 'quito',\n",
       " 'especially',\n",
       " 'levelled',\n",
       " 'antelope',\n",
       " 'obscures',\n",
       " '35',\n",
       " 'javelin',\n",
       " 'deliverer',\n",
       " 'gamming',\n",
       " 'storied',\n",
       " 'unsolicited',\n",
       " 'seaward',\n",
       " 'favour',\n",
       " 'information',\n",
       " 'comparison',\n",
       " 'honourable',\n",
       " 'bombazine',\n",
       " 'discoverer',\n",
       " 'harlot',\n",
       " 'awfulness',\n",
       " 'reasonably',\n",
       " 'huff',\n",
       " 'darting',\n",
       " 'identify',\n",
       " 'garter',\n",
       " 'sticks',\n",
       " 'dispersed',\n",
       " 'operate',\n",
       " 'woebegone',\n",
       " 'justify',\n",
       " 'untutored',\n",
       " 'unconditionally',\n",
       " 'reiterated',\n",
       " 'wavingly',\n",
       " 'bunched',\n",
       " 'brimmed',\n",
       " 'quiver',\n",
       " 'tigress',\n",
       " 'phidias',\n",
       " 'gamy',\n",
       " '1778',\n",
       " 'holiday',\n",
       " 'grasp',\n",
       " 'pitchpoled',\n",
       " 'taken',\n",
       " 'beggar',\n",
       " 'writ',\n",
       " 'excited',\n",
       " 'remaining',\n",
       " 'midships',\n",
       " 'risings',\n",
       " 'mariners',\n",
       " 'liabilities',\n",
       " 'calendar',\n",
       " 'ducat',\n",
       " 'skies',\n",
       " 'manhood',\n",
       " 'disinterred',\n",
       " 'patagonian',\n",
       " 'fathoms',\n",
       " 'congenial',\n",
       " 'term',\n",
       " 'fasces',\n",
       " 'court',\n",
       " 'bibles',\n",
       " 'canaller',\n",
       " 'gases',\n",
       " 'smuggling',\n",
       " 'tolland',\n",
       " 'palpably',\n",
       " 'abhorrent',\n",
       " 'adjoining',\n",
       " 'superlative',\n",
       " 'regarded',\n",
       " 'breezes',\n",
       " 'herr',\n",
       " 'overawing',\n",
       " 'butchers',\n",
       " 'candidate',\n",
       " 'circumference',\n",
       " 'quietude',\n",
       " 'tend',\n",
       " 'sill',\n",
       " 'care',\n",
       " 'scowl',\n",
       " 'opportunities',\n",
       " 'stash',\n",
       " 'partaking',\n",
       " 'halls',\n",
       " 'steersman',\n",
       " 'rambled',\n",
       " 'multitude',\n",
       " 'hideously',\n",
       " 'mooted',\n",
       " 'containing',\n",
       " 'milky',\n",
       " 'scuttling',\n",
       " 'breathless',\n",
       " 'loveliest',\n",
       " 'twopence',\n",
       " 'unbecomingness',\n",
       " 'atheism',\n",
       " 'antlers',\n",
       " 'popularize',\n",
       " 'dinning',\n",
       " 'semiweekly',\n",
       " 'movements',\n",
       " 'begged',\n",
       " 'pliable',\n",
       " 'greedily',\n",
       " 'driftings',\n",
       " 'nicely',\n",
       " 'strongly',\n",
       " 'undeniable',\n",
       " 'necessitated',\n",
       " 'starbuck',\n",
       " 'unprofitable',\n",
       " 'dubious',\n",
       " 'extend',\n",
       " 'garments',\n",
       " 'quarrelsome',\n",
       " 'appoint',\n",
       " 'amid',\n",
       " 'slink',\n",
       " 'afternoon',\n",
       " 'pangs',\n",
       " 'conveniences',\n",
       " 'happier',\n",
       " 'practical',\n",
       " 'relations',\n",
       " 'with',\n",
       " 'scramble',\n",
       " 'gauntleted',\n",
       " 'heartwoes',\n",
       " 'scolloped',\n",
       " 'puritanic',\n",
       " 'khan',\n",
       " 'mistakes',\n",
       " 'primal',\n",
       " 'manikin',\n",
       " 'lodgings',\n",
       " 'compassion',\n",
       " 'wheeled',\n",
       " 'day',\n",
       " 'stuff',\n",
       " 'massachusetts',\n",
       " 'running',\n",
       " 'wad',\n",
       " 'nimbly',\n",
       " 'yojo',\n",
       " 'have',\n",
       " 'adopted',\n",
       " 'iciness',\n",
       " 'booting',\n",
       " 'gunwale',\n",
       " 'cord',\n",
       " 'gleig',\n",
       " 'haunt',\n",
       " 'pier',\n",
       " 'maledictions',\n",
       " 'breach',\n",
       " 'heraldic',\n",
       " 'rapscallions',\n",
       " 'usual',\n",
       " 'unique',\n",
       " 'fail',\n",
       " 'likely',\n",
       " 'tier',\n",
       " 'morsel',\n",
       " 'cabalistically',\n",
       " 'blowing',\n",
       " 'waters',\n",
       " '24',\n",
       " 'india',\n",
       " 'plowdon',\n",
       " 'speckled',\n",
       " 'doltish',\n",
       " 'bannisters',\n",
       " 'hatchet',\n",
       " 'tyro',\n",
       " 'gentle',\n",
       " 'appellative',\n",
       " 'tucks',\n",
       " 'manchester',\n",
       " 'cabalistical',\n",
       " 'birthmark',\n",
       " 'all',\n",
       " 'impelled',\n",
       " 'thick',\n",
       " 'mingled',\n",
       " 'burly',\n",
       " 'embark',\n",
       " 'unstranded',\n",
       " 'downright',\n",
       " 'successful',\n",
       " 'seems',\n",
       " 'divinest',\n",
       " 'occupants',\n",
       " 'overtakes',\n",
       " 'feed',\n",
       " 'change',\n",
       " 'susceptible',\n",
       " 'vultures',\n",
       " 'beached',\n",
       " 'swarmed',\n",
       " 'detect',\n",
       " 'sequential',\n",
       " 'stepping',\n",
       " 'mind',\n",
       " 'travelled',\n",
       " 'bailiff',\n",
       " 'necessity',\n",
       " '60',\n",
       " 'murky',\n",
       " 'conveyance',\n",
       " 'irksome',\n",
       " 'thirteenth',\n",
       " 'incompatible',\n",
       " 'presence',\n",
       " 'proprietor',\n",
       " 'facts',\n",
       " 'torrid',\n",
       " 'physiognomically',\n",
       " 'seasons',\n",
       " 'ingloriously',\n",
       " 'towing',\n",
       " 'frequendy',\n",
       " 'mystifying',\n",
       " 'fabric',\n",
       " 'curing',\n",
       " 'permitted',\n",
       " 'quenchless',\n",
       " 'bullocks',\n",
       " 'orthodoxy',\n",
       " 'refrigerators',\n",
       " 'careless',\n",
       " 'happening',\n",
       " 'sorrow',\n",
       " 'savesoul',\n",
       " 'seven',\n",
       " 'sharing',\n",
       " 'blank',\n",
       " 'ark',\n",
       " 'considerably',\n",
       " 'leviathanism',\n",
       " 'celebrity',\n",
       " 'admonitory',\n",
       " 'innocency',\n",
       " 'toasted',\n",
       " 'druggists',\n",
       " 'excavating',\n",
       " 'whatsoever',\n",
       " 'carpenters',\n",
       " 'lookee',\n",
       " 'thrashing',\n",
       " 'intervene',\n",
       " 'impatiently',\n",
       " 'bottles',\n",
       " 'plague',\n",
       " 'smithfield',\n",
       " 'butcher',\n",
       " 'cibil',\n",
       " 'decapitated',\n",
       " 'rocket',\n",
       " 'lingering',\n",
       " 'lasts',\n",
       " 'jaffa',\n",
       " 'shrewdness',\n",
       " 'pulpy',\n",
       " 'countersunk',\n",
       " 'duty',\n",
       " 'intensity',\n",
       " 'lividly',\n",
       " 'sprout',\n",
       " 'insular',\n",
       " 'balloon',\n",
       " 'bumping',\n",
       " 'nicholas',\n",
       " 'ferocity',\n",
       " 'godly',\n",
       " 'menial',\n",
       " 'wealthiest',\n",
       " 'penem',\n",
       " 'crept',\n",
       " 'swims',\n",
       " 'subscribes',\n",
       " 'scythes',\n",
       " 'hourly',\n",
       " 'veteran',\n",
       " 'giddy',\n",
       " 'vigilant',\n",
       " 'owing',\n",
       " 'calm',\n",
       " 'treated',\n",
       " 'shavings',\n",
       " 'aggravate',\n",
       " 'alter',\n",
       " 'recurred',\n",
       " 'closes',\n",
       " 'cutlet',\n",
       " 'crockery',\n",
       " 'nonplussed',\n",
       " 'chiselled',\n",
       " 'these',\n",
       " 'withered',\n",
       " 'sirs',\n",
       " 'upraising',\n",
       " 'raised',\n",
       " 'needlessly',\n",
       " 'untattooed',\n",
       " 'sports',\n",
       " 'duels',\n",
       " 'insurance',\n",
       " 'affronted',\n",
       " 'weedy',\n",
       " ...}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is why: run this code and look at items, normaly you should find '23' and other numbers so w.lower() works on strings \n",
    "#that are numbers...( :) you got it)\n",
    "set(w.lower() for w in text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry if you don't feel confident with list comprehensions yet, since you'll see many more examples along with explanations in the following chapters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4   Looping with Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n",
      "Ishmael\n"
     ]
    }
   ],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
    ">>> for xyzzy in sent1:\n",
    "...     if xyzzy.endswith('l'):\n",
    "...         print(xyzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call is a titlecase word\n",
      "me is a lowercase word\n",
      "Ishmael is a titlecase word\n",
      ". is punctuation\n",
      "some is a lowercase word\n"
     ]
    }
   ],
   "source": [
    "for token in sent1:\n",
    "...     if token.islower():\n",
    "...         print(token, 'is a lowercase word')\n",
    "...     elif token.istitle():\n",
    "...         print(token, 'is a titlecase word')\n",
    "...     else:\n",
    "...         print(token, 'is punctuation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even with this small amount of Python knowledge, you can start to build multiline Python programs. It's important to develop such programs in pieces, testing that each piece does what you expect before combining them into a program. This is why the Python interactive interpreter is so invaluable, and why you should get comfortable using it.\n",
    "\n",
    "Finally, let's combine the idioms we've been exploring. First, we create a list of cie and cei words, then we loop over each item and print it. Notice the extra information given in the print statement: end=' '. This tells Python to print a space (not the default newline) after each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancient ceiling conceit conceited conceive conscience conscientious conscientiously deceitful deceive deceived deceiving deficiencies deficiency deficient delicacies excellencies fancied insufficiency insufficient legacies perceive perceived perceiving prescience prophecies receipt receive received receiving society species sufficient sufficiently undeceive undeceiving "
     ]
    }
   ],
   "source": [
    "tricky = sorted(w for w in set(text2) if 'cie' in w or 'cei' in w)\n",
    ">>> for word in tricky:\n",
    "...     print(word, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5   Automatic Natural Language Understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been exploring language bottom-up, with the help of texts and the Python programming language. However, we're also interested in exploiting our knowledge of language and computation by building useful language technologies. We'll take the opportunity now to step back from the nitty-gritty of code in order to paint a bigger picture of natural language processing.\n",
    "\n",
    "At a purely practical level, we all need help to navigate the universe of information locked up in text on the Web. Search engines have been crucial to the growth and popularity of the Web, but have some shortcomings. It takes skill, knowledge, and some luck, to extract answers to such questions as: What tourist sites can I visit between Philadelphia and Pittsburgh on a limited budget? What do experts say about digital SLR cameras? What predictions about the steel market were made by credible commentators in the past week? Getting a computer to answer them automatically involves a range of language processing tasks, including information extraction, inference(L'inférence est un mouvement de la pensée allant des principes à la conclusion.) , and summarization, and would need to be carried out on a scale and with a level of robustness that is still beyond our current capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a more philosophical level, a long-standing challenge within artificial intelligence has been to build intelligent machines, and a major part of intelligent behaviour is understanding language. For many years this goal has been seen as too difficult. However, as NLP technologies become more mature, and robust methods for analyzing unrestricted text become more widespread, the prospect of natural language understanding has re-emerged as a plausible goal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we describe some language understanding technologies, to give you a sense of the interesting challenges that are waiting for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1   Word Sense Disambiguation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In word sense disambiguation we want to work out which sense of a word was intended in a given context. Consider the ambiguous words serve and dish:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\t\t<i>serve</i>: help with food or drink; hold(tenir) an office; put ball into play\n",
    "\n",
    "b.\t\t<i>dish</i>: plate; course of a meal; communications device\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a sentence containing the phrase: he served the dish, you can detect that both serve and dish are being used with their food meanings. It's unlikely that the topic of discussion shifted from sports to crockery(vaisselle, آنية فخارية) in the space of three words. This would force you to invent bizarre images, like a tennis pro taking out his or her frustrations on a china tea-set laid out beside the court. In other words, we automatically disambiguate words using context, exploiting the simple fact that nearby words have closely related meanings. As another example of this contextual effect, consider the word by, which has several meanings, e.g.: the book by Chesterton (agentive — Chesterton was the author of the book); the cup by the stove (locative — the stove is where the cup is); and submit by Friday (temporal — Friday is the time of the submitting). Observe in (3c) that the meaning of the italicized word helps us interpret the meaning of by."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\t\tThe lost children were found by the <i>searchers</i> (agentive)\n",
    "\n",
    "b.\t\tThe lost children were found by the <i>mountain</i> (locative)\n",
    "\n",
    "c.\t\tThe lost children were found by the <i>afternoon</i> (temporal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Pronoun Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deeper kind of language understanding is to work out \"who did what to whom\" — i.e., to detect the subjects and objects of verbs. You learnt to do this in elementary school, but it's harder than you might think. In the sentence the thieves stole the paintings it is easy to tell who performed the stealing action. Consider three possible following sentences in (4c), and try to determine what was sold, caught, and found (one case is ambiguous).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\t\tThe thieves stole the paintings. They were subsequently <i>sold.</i>\n",
    "\n",
    "b.\t\tThe thieves stole the paintings. They were subsequently <i>caught.</i>\n",
    "\n",
    "c.\t\tThe thieves stole the paintings. They were subsequently <i>found.</i>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>The third case is ambiguous because we can not figure out who(or what) were found: thieves or paintings</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answering this question involves finding the antecedent of the pronoun they, either thieves or paintings. Computational techniques for tackling this problem include anaphora resolution — identifying what a pronoun or noun phrase refers to — and semantic role labeling — identifying how a noun phrase relates to the verb (as agent, patient, instrument, and so on).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3   Generating Language Output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can automatically solve such problems of language understanding, we will be able to move on to tasks that involve generating language output, such as question answering and machine translation. In the first case, a machine should be able to answer a user's questions relating to collection of texts:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\t\t<i>Text</i>: ... The thieves stole the paintings. They were subsequently sold. ...\n",
    "\n",
    "b.\t\t<i>Human</i>: Who or what was sold?\n",
    "\n",
    "c.\t\t<i>Machine</i>: The paintings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine's answer demonstrates that it has correctly worked out that they refers to paintings and not to thieves. In the second case, the machine should be able to translate the text into another language, accurately conveying the meaning of the original text. In translating the example text into French, we are forced to choose the gender of the pronoun in the second sentence: ils (masculine) if the thieves are found, and elles (feminine) if the paintings are found. Correct translation actually depends on correct understanding of the pronoun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\t\tThe thieves stole the paintings. They were subsequently found.\n",
    "\n",
    "b.\t\tLes voleurs ont volé les peintures. Ils ont été trouvés plus tard. (the thieves)\n",
    "\n",
    "c.\t\tLes voleurs ont volé les peintures. Elles ont été trouvées plus tard. (the paintings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of these examples, working out the sense of a word, the subject of a verb, and the antecedent of a pronoun are steps in establishing the meaning of a sentence, things we would expect a language understanding system to be able to do.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4   Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a long time now, machine translation (MT) has been the holy grail of language understanding, ultimately seeking to provide high-quality, idiomatic translation between any pair of languages. Its roots go back to the early days of the Cold War, when the promise of automatic translation led to substantial government sponsorship, and with it, the genesis of NLP itself.\n",
    "\n",
    "Today, practical translation systems exist for particular pairs of languages, and some are integrated into web search engines. However, these systems have some serious shortcomings, which are starkly revealed by translating a sentence back and forth between a pair of languages until equilibrium is reached, e.g.:\n",
    "\n",
    "0> how long before the next flight to Alice Springs? </br>\n",
    "\n",
    "1> wie lang vor dem folgenden Flug zu Alice Springs?</br>\n",
    "\n",
    "2> how long before the following flight to Alice jump?</br>\n",
    "\n",
    "3> wie lang vor dem folgenden Flug zu Alice springen Sie?</br>\n",
    "\n",
    "4> how long before the following flight to Alice do you jump?</br>\n",
    "\n",
    "5> wie lang, bevor der folgende Flug zu Alice tun, Sie springen?</br>\n",
    "\n",
    "6> how long, before the following flight to Alice does, do you jump?</br>\n",
    "\n",
    "7> wie lang bevor der folgende Flug zu Alice tut, tun Sie springen?</br>\n",
    "\n",
    "8> how long before the following flight to Alice does, do you jump?</br>\n",
    "\n",
    "9> wie lang, bevor der folgende Flug zu Alice tut, tun Sie springen?</br>\n",
    "\n",
    "10> how long, before the following flight does to Alice, do do you jump?</br>\n",
    "\n",
    "11> wie lang bevor der folgende Flug zu Alice tut, Sie tun Sprung?</br>\n",
    "\n",
    "12> how long before the following flight does leap to Alice, does you?</br>\n",
    "\n",
    "Observe that the system correctly translates Alice Springs from English to German (in the line starting 1>), but on the way back to English, this ends up as Alice jump (line 2). The preposition before is initially translated into the corresponding German preposition vor, but later into the conjunction bevor (line 5). After line 5 the sentences become nonsensical (but notice the various phrasings indicated by the commas, and the change from jump to leap). The translation system did not recognize when a word was part of a proper name, and it misinterpreted the grammatical structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine translation is difficult because a given word could have several possible translations (depending on its meaning), and because word order must be changed in keeping with the grammatical structure of the target language. Today these difficulties are being faced by collecting massive quantities of parallel texts from news and government websites that publish documents in two or more languages. Given a document in German and English, and possibly a bilingual dictionary, we can automatically pair up the sentences, a process called text alignment. Once we have a million or more sentence pairs, we can detect corresponding words and phrases, and build a model that can be used for translating new text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
